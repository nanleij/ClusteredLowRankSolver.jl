var documenterSearchIndex = {"docs":
[{"location":"references/#References-and-citing","page":"References and citing","title":"References and citing","text":"","category":"section"},{"location":"references/","page":"References and citing","title":"References and citing","text":"The semidefinite programming solver and the interface (including sampled polynomials) in ClusteredLowRankSolver.jl have been developed as part of the paper","category":"page"},{"location":"references/","page":"References and citing","title":"References and citing","text":"Nando Leijenhorst and David de Laat, Solving clustered low-rank semidefinite programs arising from polynomial optimization, preprint, 2022. arXiv:2202.12077","category":"page"},{"location":"references/","page":"References and citing","title":"References and citing","text":"The solver was inspired by the more specialized solver","category":"page"},{"location":"references/","page":"References and citing","title":"References and citing","text":"David Simmons-Duffin. A semidefinite program solver for the conformal bootstrap. J. High Energy Phys. 174 (2015), arXiv:1502.02033","category":"page"},{"location":"references/","page":"References and citing","title":"References and citing","text":"The rounding procedure in ClusteredLowRankSolver.jl has been developed as part of the paper","category":"page"},{"location":"references/","page":"References and citing","title":"References and citing","text":"Henry Cohn, David de Laat, and Nando Leijenhorst, Optimality of spherical codes via exact semidefinite programming bounds, preprint, 2024. arXiv:???","category":"page"},{"location":"references/","page":"References and citing","title":"References and citing","text":"This improves the rounding procedure developed in","category":"page"},{"location":"references/","page":"References and citing","title":"References and citing","text":"Maria Dostert, David de Laat, and Philippe Moustrou, Exact semidefinite programming bounds for packing problems, SIAM J. Optim. 31(2) (2021), 1433-1458, arXiv:2001.00256","category":"page"},{"location":"references/#References","page":"References and citing","title":"References","text":"","category":"section"},{"location":"references/","page":"References and citing","title":"References and citing","text":"H. Cohn, D. de Laat and N. Leijenhorst. Optimality of spherical codes via exact semidefinite programming bounds, arXiv:2403.16874 (2024).\n\n\n\nD. de Laat and N. Leijenhorst. Solving clustered low-rank semidefinite programs arising from polynomial optimization, arXiv:2202.12077 (2022).\n\n\n\nD. Simmons-Duffin. A semidefinite program solver for the conformal bootstrap. Journal of High Energy Physics 2015, 174 (2015).\n\n\n\nP. Delsarte, J. M. Goethals and J. J. Seidel. Spherical codes and designs. Geometriae Dedicata 6, 363–388 (1977).\n\n\n\nD. de Laat, F. M. de Oliveira Filho and F. Vallentin. Upper bounds for packings of spheres of several radii. Forum of Mathematics, Sigma 2, e23 (2014).\n\n\n\nH. Cohn and N. Elkies. New upper bounds on sphere packings. I. Annals of Mathematics (2) 157, 689–714 (2003).\n\n\n\nK. Gatermann and P. A. Parrilo. Symmetry groups, semidefinite programs, and sums of squares. Journal of Pure and Applied Algebra 192, 95–128 (2004).\n\n\n\n","category":"page"},{"location":"sdpa/#Using-SDPA-sparse-format","page":"SDPA-sparse format","title":"Using SDPA-sparse format","text":"","category":"section"},{"location":"sdpa/","page":"SDPA-sparse format","title":"SDPA-sparse format","text":"The function sdpa_sparse_to_problem can be used to read an SDPA-sparse file and create a Problem. In particular, this makes it possible to use JuMP to create a semidefinite program and write it to the SDPA-sparse format, which can then be read and solved with ClusteredLowRankSolver. The JuMP interface is not yet supported for direct conversion to a Problem.","category":"page"},{"location":"sdpa/","page":"SDPA-sparse format","title":"SDPA-sparse format","text":"sdpa_sparse_to_problem","category":"page"},{"location":"sdpa/#ClusteredLowRankSolver.sdpa_sparse_to_problem","page":"SDPA-sparse format","title":"ClusteredLowRankSolver.sdpa_sparse_to_problem","text":"sdpa_sparse_to_problem(filename,obj_shift = 0; T=Float64)\n\nDefine the Problem from the file filename assuming it is in SDPA sparse format, using the number type T. Optionally add an objective shift. \n\n\n\n\n\n","category":"function"},{"location":"examples/delsarte/#exdelsarte","page":"Delsarte LP bound","title":"Example: the Delsarte bound","text":"","category":"section"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"In this example we show how the Delsarte linear programming bound [4] for the spherical code problem can be modeled and solved using ClusteredLowRankSolver. See the Examples folder for the file with the code. Let P_k^n be the Gegenbauer polynomial of degree k with parameter n2-1, normalized such that P_k^n(1) = 1. The Delsarte bound for dimension n, degree 2d, and angle theta can be written as","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"beginaligned\n    min quad  M  \n    textst quadsum_k=1^2d a_k P_k^n(x) leq -1  quad x in -1cos(theta)\n      sum_k=1^2d a_k  -  M leq -1 \n     a_k geq 0\nendaligned","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"This gives an upper bound on the size of a spherical code on S^n-1 with x cdot yleqcos(theta) for any distinct x and y. Note that we could remove the free variable M by using the objective 1+sum_k a_k, but for illustration purposes we include this free variable in the formulation.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"To model this as a clustered low-rank semidefinite program, we equate the polynomial","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"- 1 - sum_k a_k P^n_k(x)","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"to the weighted sums-of-squares polynomial","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"langle Y_1b(x)b(x)^T rangle + (x+1)(cos(theta)-x) langle Y_2b(x)b(x)^Trangle","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"for a vector of basis polynomials b(x). By a theorem of Lukács, one can always write the polynomial in this form. Moreover, we can truncate the vectors b(x) such that both terms have degree at most 2d. Then we sample the polynomials on 2d+1 points x_1ldotsx_2d+1 in -1cos(theta) to obtain semidefinite constraints (any set of 2d+1 distinct points is minimal unisolvent for the univariate polynomials up to degree 2d).","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"Furthermore, to model the linear inequality constraint, we introduce a slack variable s geq 0 such that we need sum_k=1^2d a_k + s - M = -1. Together this gives the semidefinite program","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"beginaligned\n    min quad  M  \n    textst sum_k=1^2d a_k P_k^n(x_l) + langle b_d(x_l)b_d(x_l)^T Y_1 rangle \n    quad + langle g(x_l)b_d-1(x_l)b_d-1(x_l)^T Y_2 rangle = -1quad l=1 ldots 2d+1 \n      sum_k=1^2d a_k + s - M  =-1 quad \n     a_k geq 0\n     s geq 0 \n     Y_i succeq 0 i=12\nendaligned","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"where b_d is a basis of polynomials up to degree d and","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"g(x) = (x+1)(cos(theta)-x)","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"Now that we formulated the semidefinite program, we can model it in Julia. We use the polynomial_ring of AbstractAlgebra to define the polynomials. We will start with the objective and constraints after which we define the complete program.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"The objective is simple, since we only optimize the value of the free variable M. This gives the start of our script:","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"using ClusteredLowRankSolver, AbstractAlgebra\n\nfunction delsarte(n, d, costheta)\n\n    # Initialize the objective with additive constant 0,\n    # no dependence on matrix variables,\n    # and dependence with coefficient 1 on the free variable :M\n    obj = Objective(0, Dict(), Dict(:M => 1))\n","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"For the first constraint, we need the Gegenbauer polynomials, which are part of ClusteredLowRankSolver. In this constraint we only use the positive semidefinite matrix variables, for which we collect the constraint matrices in a Dict:","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    R, x = polynomial_ring(RealField, :x)\n    # A vector consisting of the Gegenbauer polynomials\n    # of degree at most 2d\n    gp = basis_gegenbauer(2d, n, x)\n    psd_dict1 = Dict()\n    for k = 1:2d\n        psd_dict1[(:a, k)] = [gp[k+1];;]\n    end","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"Note that here we use a general (high-rank) constraint matrix for the variables a_k. For the sums-of-squares part, we define a basis and the set of samples points. We use approximatefekete to obtain a basis which is orthogonal with respect to the sample points.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    # 2d+1 Chebyshev points in the interval [-1, cos(θ)]\n    samples = sample_points_chebyshev(2d, -1, costheta)\n    # A basis for the Chebyshev polynomials of degree at most 2d\n    basis = basis_chebyshev(2d, x)\n    # Optimize the basis with respect to the samples\n    sosbasis, samples = approximatefekete(basis, samples)","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"Since the second sum-of-squares has a weight of degree 2, we use a basis up to degree d-1 in that case.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    psd_dict1[(:SOS, 1)] = LowRankMatPol([1], [sosbasis[1:d+1]])\n    psd_dict1[(:SOS, 2)] = LowRankMatPol([(1+x)*(costheta-x)], [sosbasis[1:d]])\n    constr1 = Constraint(-1, psd_dict1, Dict(), samples)","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"In the last line, we define the constraint (with constant polynomial -1). The extra dictionary corresponds to the coefficients for the free variables, which we do not use in this constraint.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"The second constraint looks simpler since it does not involve polynomials. We also introduce a slack variable, this gives the constraint sum_k a_k + s - M = -1, where s geq 0.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    # The free variable M has coefficient -1:\n    free_dict2 = Dict(:M => -1)\n    # The variables a_k and the slack variable have coefficient 1:\n    psd_dict2 = Dict()\n    for k = 1:2d\n        psd_dict2[(:a, k)] = [1;;]\n    end\n    psd_dict2[:slack] = [1;;]\n    constr2 = Constraint(-1, psd_dict2, free_dict2)","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"Note that we again use a general matrix for the variables a_k. The use of low-rank matrices and general matrices should be consistent per variable. Now we can define the Problem.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    problem = Problem(Minimize(obj), [constr1, constr2])","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"and solve the corresponding semidefinite program with","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    status, primalsol, dualsol, time, errorcode = solvesdp(problem)","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"after which we return the objective value.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    return objvalue(problem, dualsol)\nend\nnothing # hide","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"Alternatively, we can first create the semidefinite program with","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"    sdp = ClusteredLowRankSDP(problem)","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"after which we can call solvesdp on sdp.","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"Running this for one of the known sharp cases gives","category":"page"},{"location":"examples/delsarte/","page":"Delsarte LP bound","title":"Delsarte LP bound","text":"delsarte(8, 3, 1//2)","category":"page"},{"location":"advancedmodeling/#Advanced-modeling","page":"Advanced modeling","title":"Advanced modeling","text":"","category":"section"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"Here some more advanced modeling concepts are explained. Please see the Tutorial for basic usage.","category":"page"},{"location":"advancedmodeling/#Block-structure","page":"Advanced modeling","title":"Block structure","text":"","category":"section"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"In some cases, there is low-rank structure in the constraint matrices, but it is only obvious when considering submatrices. This is for example the case when using sums-of-squarse for polynomial matrix constraints (see the sphere packing example). In these situations the Block struct can be used to specify to which subblock the given constraint matrix corresponds. In all versions of ClusteredLowRankSolver, only a subblock structure with equal sized blocks is allowed.","category":"page"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"Block","category":"page"},{"location":"advancedmodeling/#ClusteredLowRankSolver.Block","page":"Advanced modeling","title":"ClusteredLowRankSolver.Block","text":"Block(l::Any[, r::Int, s::Int])\n\nSpecifies a block corresponding to the positive semidefinite variable l.\n\nSpecifying r,s makes the Block correspond to the r,s subblock of the variable l.\n\n\n\n\n\n","category":"type"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"note: Note\nFor version 0.x, using the Block struct was required for specifying the names of the positive semidefinite variables. This is no longer the case in version 1.0+.","category":"page"},{"location":"advancedmodeling/#Sampling","page":"Advanced modeling","title":"Sampling","text":"","category":"section"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"For the samples, we need a minimal unisolvent set of points for the polynomial vector space spanned by the entries of the coefficients in the constraint. A set of points is unisolvent for a space of polynomials if the only polynomial which evaluates to 0 on all the points is the zero polynomial. Such a set is minimal if any strict subset is not unisolvent. In general, it is possible to test whether a set of points is unisolvent by creating the Vandermonde matrix (b_j(x_i))_ij and checking whether it is nonsingular. This matrix is also used by approximatefekete to select a subset of good sample points and a correspondingly good basis. ","category":"page"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"There are three main approaches to create a unisolvent set of points. First, one can take a number of random samples (at least equal to the dimension of the polynomial space considered in the constraint). This is a unisolvent set with probability 1, and by using the function approximatefekete it is possible to select a minimal unisolvent subset of these points, together with a good basis. The second approach is to take a grid of points, and again use approximatefekete to select a minimal unisolvent subset.  Lastly, one can use a set known to be unisolvent, such as the chebyshev points for univariate polynomials (sample_points_chebyshev), padua points for bivariate polynomials (sample_points_padua), or the rational points in the simplex with denominator 1d for multivariate polynomials of degree at most d (sample_points_simplex).","category":"page"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"approximatefekete\napproximatefeketeexact\nsample_points_chebyshev\nsample_points_padua\nsample_points_simplex","category":"page"},{"location":"advancedmodeling/#ClusteredLowRankSolver.approximatefekete-advancedmodeling","page":"Advanced modeling","title":"ClusteredLowRankSolver.approximatefekete","text":"approximatefekete(basis, samples; base_ring=BigFloat) -> basis, samples\n\nCompute approximate fekete points based on samples and a corresponding orthogonal basis. The basis consists of sampled polynomials, sampled at samples.\n\nThis preserves a degree ordering of basis if present.\n\n\n\n\n\n","category":"function"},{"location":"advancedmodeling/#ClusteredLowRankSolver.approximatefeketeexact-advancedmodeling","page":"Advanced modeling","title":"ClusteredLowRankSolver.approximatefeketeexact","text":"approximatefeketeexact(R, basis, samples)\n\nApply approximate fekete but return an exact basis transformation.\n\n\n\n\n\n","category":"function"},{"location":"advancedmodeling/#ClusteredLowRankSolver.sample_points_chebyshev-advancedmodeling","page":"Advanced modeling","title":"ClusteredLowRankSolver.sample_points_chebyshev","text":"sample_points_chebyshev(d, a = -1, b = 1; T=BigFloat) -> Vector{T}\n\nGenerate the d+1 Chebyshev points in [a,b].\n\n\n\n\n\n","category":"function"},{"location":"advancedmodeling/#ClusteredLowRankSolver.sample_points_padua-advancedmodeling","page":"Advanced modeling","title":"ClusteredLowRankSolver.sample_points_padua","text":"sample_points_padua(d; T=BigFloat) -> Vector{Vector{T}}\n\nGenerate the Padua points for degree d.\n\n\n\n\n\n","category":"function"},{"location":"advancedmodeling/#ClusteredLowRankSolver.sample_points_simplex-advancedmodeling","page":"Advanced modeling","title":"ClusteredLowRankSolver.sample_points_simplex","text":"sample_points_simplex(n, d; T=BigFloat) -> Vector{Vector{T}}\n\nGenerate the rational sample points in the unit simplex with denominator d.\n\n\n\n\n\n","category":"function"},{"location":"advancedmodeling/#Sampled-polynomials","page":"Advanced modeling","title":"Sampled polynomials","text":"","category":"section"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"Sampling large polynomials can become the bottleneck of building the semidefinite program. To speed this up, it is possible to work with sampled polynomials. Functionality includes basic operations such as multiplication, addition and subtraction, but also evaluating a polynomial on a sampled polynomial. Below we show some examples of how such a sampled polynomial can be constructed.","category":"page"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"using AbstractAlgebra, ClusteredLowRankSolver\nR, x = polynomial_ring(RealField, :x)\nsamples = sample_points_chebyshev(10)\n# The samples need to be sorted for the sampled polynomial ring for faster evaluations\nsort!(samples) \nRsampled = sampled_polynomial_ring(RealField, samples)\n# options to construct a sampled polynomial:\n# (partially) construct a polynomial and convert it to a sampled polynomial\np = 1+x^2 \npsampled = Rsampled(p)\n# convert the generator and work with that\nxs = Rsampled(x)\npsampled2 = 1+xs^2\n# evaluate a polynomial on a sampled polynomial\npsampled3 = p(xs)\n# construct the polynomial from evaluations:\nevals = [1+i^2 for i in samples]\npsampled4 = SampledMPolyRingElem(Rsampled, evals)\nlength(unique([psampled, psampled2, psampled3, psampled4])) == 1","category":"page"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"Note that it should be possible to evaluate polynomials over the base ring of the sampled polynomial ring on the samples. For example, it is not possible to use floating point samples with an exact base ring. A sampled polynomial can only be evaluated at the samples used in the sampled polynomial ring.","category":"page"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"sampled_polynomial_ring\nSampledMPolyRingElem","category":"page"},{"location":"advancedmodeling/#ClusteredLowRankSolver.sampled_polynomial_ring","page":"Advanced modeling","title":"ClusteredLowRankSolver.sampled_polynomial_ring","text":"sampled_polynomial_ring(base_ring, samples)\n\nCreate a SampledMPolyRing with values in base_ring defined on samples. The samples should be sorted.\n\n\n\n\n\n","category":"function"},{"location":"advancedmodeling/#ClusteredLowRankSolver.SampledMPolyRingElem","page":"Advanced modeling","title":"ClusteredLowRankSolver.SampledMPolyRingElem","text":"SampledMPolyRinElem(parent::SampledMPolyRing, evaluations::Vector)\n\nA sampled polynomial corresponding to the given parent, which evaluates to evaluations on the samples of the parent ring.\n\n\n\n\n\n","category":"type"},{"location":"advancedmodeling/#Clustering","page":"Advanced modeling","title":"Clustering","text":"","category":"section"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"In the ClusteredLowRankSDP, the constraints are clustered. That is, two constraints in different clusters do not use the same positive semidefinite matrix variables. Internally, this creates a block structure which can be exploited by the solver. One example where clustering occurs is when sampling multiple polynomial constraints which do not use positive semidefinite variables other than the ones for sum-of-squares characterizations. If other positive semidefinite variables are used, it might be beneficial to use extra free variables in the constraint instead of the positive semidefinite matrix variables, and add constraint to equate these variables to entries of the positive semidefinite matrix variables. This is supported through the function model_psd_variables_as_free_variables!. See the example about Clustering. ","category":"page"},{"location":"advancedmodeling/","page":"Advanced modeling","title":"Advanced modeling","text":"model_psd_variables_as_free_variables!","category":"page"},{"location":"advancedmodeling/#ClusteredLowRankSolver.model_psd_variables_as_free_variables!","page":"Advanced modeling","title":"ClusteredLowRankSolver.model_psd_variables_as_free_variables!","text":"model_psd_variables_as_free_variables!(problem::Problem, as_free)\n\nModel the positive semidefinite variables with names in as_free using free variables,  and add extra constraints to set them equal to auxilliary positive semidefinite variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules=[ClusteredLowRankSolver]\nPrivate=false","category":"page"},{"location":"api/#ClusteredLowRankSolver.Block-api","page":"API reference","title":"ClusteredLowRankSolver.Block","text":"Block(l::Any[, r::Int, s::Int])\n\nSpecifies a block corresponding to the positive semidefinite variable l.\n\nSpecifying r,s makes the Block correspond to the r,s subblock of the variable l.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.ClusteredLowRankSDP-Tuple{Problem}-api","page":"API reference","title":"ClusteredLowRankSolver.ClusteredLowRankSDP","text":"ClusteredLowRankSDP(problem::Problem; prec=precision(BigFloat), verbose=false)\n\nDefine a ClusteredLowRankSDP based on problem.\n\nKeyword arguments:\n\nprec (default: precision(BigFloat)): the precision of the result\nverbose (default: false): print progress to the standard output\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.Constraint-api","page":"API reference","title":"ClusteredLowRankSolver.Constraint","text":"Constraint(constant, matrixcoeff, freecoeff[, samples, scalings])\n\nModels a polynomial constaint of the form\n\n    _i  A_i(x) Y_i   + _j b_j(x) y_j = c(x)\n\nusing sampling on samples. Here the samples are only required if A_i, b_j, and c are polynomials. When the coefficient matrix A_i has block structure with equal sized blocks, the Block struct can be used as key to indicate to which subblock the given matrix corresponds.\n\nArguments:\n\nconstant: The right hand side c(x)\nmatrixcoeff::Dict: The coefficient matrices for the positive semidefinite matrix variables.\nfreecoeff::Dict: The coefficients for the free variables.\nsamples::Vector: The sample set on which the constraint should be satisfied. Required for polynomial constraints.\nscalings::Vector: Optional; scale the constraint with a factor depending on the sample index.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.DualSolution-api","page":"API reference","title":"ClusteredLowRankSolver.DualSolution","text":"DualSolution{T}\n\nA dual solution to the semidefinite program, with fields\n\nbase_ring\nmatrixvars::Dict{Any, Matrix{T}}\nfreevars::Dict{Any, T}\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.LowRankMatPol-api","page":"API reference","title":"ClusteredLowRankSolver.LowRankMatPol","text":"LowRankMatPol(lambda::Vector, vs::Vector{Vector}[, ws::Vector{Vector}])\n\nThe matrix _i λ_i v_i w_i^sf T where v_i are the entries of vs and w_i the entries of ws\n\nIf ws is not specified, use ws = vs.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.Maximize-api","page":"API reference","title":"ClusteredLowRankSolver.Maximize","text":"Maximize(obj)\n\nMaximize the objective\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.Minimize-api","page":"API reference","title":"ClusteredLowRankSolver.Minimize","text":"Minimize(obj)\n\nMinimize the objective\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.Objective-api","page":"API reference","title":"ClusteredLowRankSolver.Objective","text":"Objective(constant, matrixcoeff::Dict, freecoeff::Dict)\n\nThe objective for the Problem.\n\nArguments:\n\nconstant: A constant offset of the objective value.\nmatrixcoeff: A Dict with positive semidefinite matrix variable names as keys and the objective matrices as values.\nfreecoeff: A Dict with free variable names as keys and the coefficients as values.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.PrimalSolution-api","page":"API reference","title":"ClusteredLowRankSolver.PrimalSolution","text":"PrimalSolution{T}\n\nA primal solution to the semidefinite program, with fields\n\nbase_ring\nx::Vector{T}\nmatrixvars::Dict{Any, Matrix{T}}\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.Problem-api","page":"API reference","title":"ClusteredLowRankSolver.Problem","text":"    Problem(maximize::Bool, objective::Objective, constraints::Vector{Constraint})\n\n    Problem(obj::Union{Maximize, Minimize}, constraints::Vector)\n\nCombine the objective and constraints into a low-rank polynomial problem.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.RoundingSettings-api","page":"API reference","title":"ClusteredLowRankSolver.RoundingSettings","text":"RoundingSettings(settings...)\n\nSettings for the rounding procedure:\n\nFinding the kernel\nkernel_errbound: (default: 1e-10) the allowed error for the kernel vectors. That is, the maximum entry of Xv is in absolute value at most this\nkernel_round_errbound: (default: 1e-15) the maximum allowed error when rounding the reduced row-echelon form entrywise\nkernel_use_primal: (default: true) use the primal solution to find the kernel vectors  (otherwise, use an SVD of the dual solution)\nkernel_lll: (default: false) if true, use the LLL algorithm to find the nullspace of the kernel. Otherwise, use the reduced row-echelon form to find kernel vectors.\nkernel_bits: (default: 1000) the maximum number of bits to be used in the LLL algorithm (for finding relations or finding the entries of the RREF)\nReducing the kernel vectors\nreduce_kernelvectors: (default: true) apply the reduction step or not\nreduce_kernelvectors_cutoff: (default: 400) do reduction on the full matrix if its size is at most this cutoff. Otherwise do it on a submatrix\nreduce_kernelvectors_stepsize: (default: 200) the number of extra columns to take into account in each iteration of the reduction step\nTransforming the problem and the solution\nunimodular_transform: (default: true) use a unimodular transform obtained in the reduction step\nnormalize_transformation: (default: true) multiply by a diagonal matrix to get an integer transformation for the problem (for problems over QQ)\nFinding an approximate solution in the field\nregularization: (default: 1e-20) use this regularization for solving the extended system\napproximation_decimals: (default: 40) Approximate the numerical solution using this many digits, entrywise\nRounding the solution to the affine space of constraints\nredundancyfactor: (default: 10) take at least this times the number of constraints columns as potential pivots\npseudo: (default: true) use the psuedo inverse for rounding (this may give solutions with larger bitsize than needed)\npseudo_columnfactor: (default: 1.05) For a system of r rows, use r * pseudo_columnfactor number of columns for the pseudo inverse\nextracolumns_linindep: (default: false) if true, take the extra columns linearly independent of each other (otherwise, random columns)\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.SampledMPolyRing-api","page":"API reference","title":"ClusteredLowRankSolver.SampledMPolyRing","text":"SampledMPolyRing(base_ring, samples)\n\nA sampled polynomial ring with evaluations in base_ring, only defined on the samples. The samples should be sorted. \n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.SampledMPolyRingElem-api","page":"API reference","title":"ClusteredLowRankSolver.SampledMPolyRingElem","text":"SampledMPolyRinElem(parent::SampledMPolyRing, evaluations::Vector)\n\nA sampled polynomial corresponding to the given parent, which evaluates to evaluations on the samples of the parent ring.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.SolverFailure-api","page":"API reference","title":"ClusteredLowRankSolver.SolverFailure","text":"SolverFailure(msg)\n\nAn error in the solver, with a message.\n\n\n\n\n\n","category":"type"},{"location":"api/#ClusteredLowRankSolver.addconstraint!-Tuple{Problem, Constraint}-api","page":"API reference","title":"ClusteredLowRankSolver.addconstraint!","text":"addconstraint!(problem, constraint)\n\nAdd constraint to the constraints of problem. \n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.approximatefekete-Tuple{Any, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.approximatefekete","text":"approximatefekete(basis, samples; base_ring=BigFloat) -> basis, samples\n\nCompute approximate fekete points based on samples and a corresponding orthogonal basis. The basis consists of sampled polynomials, sampled at samples.\n\nThis preserves a degree ordering of basis if present.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.approximatefeketeexact-Tuple{Any, Any, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.approximatefeketeexact","text":"approximatefeketeexact(R, basis, samples)\n\nApply approximate fekete but return an exact basis transformation.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.as_dual_solution-Union{Tuple{T}, Tuple{DualSolution, Vector{T}}} where T-api","page":"API reference","title":"ClusteredLowRankSolver.as_dual_solution","text":"as_dual_solution(sol, x)\n\nUndo the vectorization of x.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.basic_embedding-Tuple{Any}-api","page":"API reference","title":"ClusteredLowRankSolver.basic_embedding","text":"basic_embedding(exactvalue)\n\nConvert the exact (rational or integer) numbers to floating point approximations.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.basis_chebyshev-Tuple{Int64, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.basis_chebyshev","text":"basis_chebyshev(d::Int,x)\n\nGenerate a basis of Chebyshev polynomials of the first kind up to degree d (inclusive). \n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.basis_gegenbauer-Tuple{Any, Any, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.basis_gegenbauer","text":"basis_gegenbauer(d, n, x)\n\nBasis for the Gegenbauer polynomials in dimension n up to degree d.  This is the Gegenbauer polynomial with parameter lambda = n/2-1,  or the Jacobi polynomial with alpha = beta = (n-3)/2.  Normalized to evaluate to 1 at 1.  Taken from arxiv/2001.00256, ancillary files, SemidefiniteProgramming.jl.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.basis_jacobi-Tuple{Integer, Any, Any, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.basis_jacobi","text":"basis_jacobi(d::Integer, alpha, beta, x)\n\nGenerate the Jacobi polynomials with parameters alpha and beta up to degree d (inclusive). \n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.basis_laguerre-Tuple{Integer, Any, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.basis_laguerre","text":"basis_laguerre(d::Integer, alpha, x)\n\nGenerate the (generalized) Laguerre polynomials with parameter alpha up to degree d (inclusive). \n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.basis_monomial-Tuple{Int64, Vararg{Any}}-api","page":"API reference","title":"ClusteredLowRankSolver.basis_monomial","text":"basis_monomial(d::Int, x...)\n\nGenerate the monomial basis in variables x... up to degree d (inclusive).\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.blocksizes-Tuple{Problem}-api","page":"API reference","title":"ClusteredLowRankSolver.blocksizes","text":"blocksizes(problem)\n\nReturn the sizes of the matrix variables as a dictionary with the same keys\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.check_problem-Tuple{Problem}-api","page":"API reference","title":"ClusteredLowRankSolver.check_problem","text":"check_problem(problem::LowRankPolProblem)\n\nCheck for obvious mistakes in the constraints and objective\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.check_sdp!-Tuple{ClusteredLowRankSDP}-api","page":"API reference","title":"ClusteredLowRankSolver.check_sdp!","text":"check_sdp!(sdp::ClusteredLowRankSDP)\n\nCheck whether the constraint matrices are symmetric, and remove empty constraint matrices.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.constraints-Tuple{Problem}-api","page":"API reference","title":"ClusteredLowRankSolver.constraints","text":"constraints(problem::Problem)\n\nReturn the constraints of problem.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.convert_to_prec-api","page":"API reference","title":"ClusteredLowRankSolver.convert_to_prec","text":"convert_to_prec(sdp, prec=precision(BigFloat))\n\nConvert the semidefinite program to a semidefinite program with prec bits of precision, without error bounds.\n\n\n\n\n\n","category":"function"},{"location":"api/#ClusteredLowRankSolver.exact_solution-Tuple{Problem, PrimalSolution, DualSolution}-api","page":"API reference","title":"ClusteredLowRankSolver.exact_solution","text":"exact_solution(problem::Problem, primalsol::PrimalSolution, dualsol::DualSolution; transformed=false, FF = QQ, g=1, settings::RoundingSettings=RoundingSettings(), monomial_bases=nothing)\n\nCompute and return an exact solution to the problem, given a primal solution, dual solution and a field FF with approximate generator g. Return (success, exactdualsol) if transformed=false, and (success, pd_transformed_exactsolution, transformations) if transformed=true.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.find_field-Union{Tuple{T}, Tuple{PrimalSolution{T}, DualSolution{T}}, Tuple{PrimalSolution{T}, DualSolution{T}, Any}} where T-api","page":"API reference","title":"ClusteredLowRankSolver.find_field","text":"find_field(primalsol, dualsol, max_degree=4; valbound=1e-15, errbound=1e-15, bits=100, max_coeff=1000)\n\nHeuristically find a field over which the kernel can probably be defined. \n\nOnly consider values at least valbound in absolute value. Find minimal polynomials  such that the chosen entries are approximately generators with an error bound of errbound. Use bits number of bits and reject minimal polynomials with a maximum coefficient of more than max_coeff.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.freecoeff-Tuple{Union{Constraint, Objective}, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.freecoeff","text":"freecoeff(x::Union{Constraint, Objective}, name)\n\nReturn the coefficient of the free variable corresponding to name\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.freecoeffs-Tuple{Union{Constraint, Objective}}-api","page":"API reference","title":"ClusteredLowRankSolver.freecoeffs","text":"freecoeffs(x::Union{Constraint, Objective})\n\nReturn the dictionary of coefficients for the free variables\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.freevar-Tuple{DualSolution, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.freevar","text":"freevar(sol, name)\n\nReturn the free variable corresponding to name\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.freevars-Tuple{DualSolution}-api","page":"API reference","title":"ClusteredLowRankSolver.freevars","text":"freevars(sol)\n\nReturn the dictionary of the free variables\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.generic_embedding-Tuple{AbstractAlgebra.MPolyRingElem, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.generic_embedding","text":"generic_embedding(exactvalue, g; base_ring=BigFloat)\n\nConvert the exact numbers from a number field to floating point approximations,  using a floating point approximation of a generator g of the field.\n\nConvert rationals and integers to the same numbers in base_ring.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.linearsystem-Tuple{Problem}-api","page":"API reference","title":"ClusteredLowRankSolver.linearsystem","text":"linearsystem(problem::Problem, FF=QQ)\n\nLet x be the vcat of the vectorizations of the matrix variables. This function returns the matrix A and vector b such that the constraints are given by the system Ax = b (over the field FF).\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.linearsystem_coefficientmatching-Tuple{Problem, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.linearsystem_coefficientmatching","text":"linearsystem_coefficientmatching(problem::Problem, monomial_basis::Vector{Vector{MPolyRingElem}}; FF=QQ)\n\nLet x be the vcat of the vectorizations of the matrix variables. This function returns the matrix A and vector b such that the constraints obtained  from coefficient matching are given by the system Ax = b over the field FF, with  one constraint per monomial in monomial_basis. The problem should not contain  SampledMPolyRingElem's for this to work.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.matrixcoeff-Tuple{Union{Constraint, Objective}, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.matrixcoeff","text":"matrixcoeff(x::Union{Constraint, Objective}, name)\n\nReturn the matrix coefficient corresponding to name\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.matrixcoeffs-Tuple{Union{Constraint, Objective}}-api","page":"API reference","title":"ClusteredLowRankSolver.matrixcoeffs","text":"matrixcoeffs(x::Union{Constraint, Objective})\n\nReturn the dictionary of matrix coefficients\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.matrixvar-Tuple{DualSolution, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.matrixvar","text":"matrixvar(sol, name)\n\nReturn the matrix variable corresponding to name\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.matrixvars-Tuple{DualSolution}-api","page":"API reference","title":"ClusteredLowRankSolver.matrixvars","text":"matrixvars(sol)\n\nReturn the dictionary of matrix variables\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.model_psd_variables_as_free_variables!-Tuple{Problem, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.model_psd_variables_as_free_variables!","text":"model_psd_variables_as_free_variables!(problem::Problem, as_free)\n\nModel the positive semidefinite variables with names in as_free using free variables,  and add extra constraints to set them equal to auxilliary positive semidefinite variables.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.objective-Tuple{Union{Maximize, Minimize, Problem}}-api","page":"API reference","title":"ClusteredLowRankSolver.objective","text":"objective(x::Union{Maximize, Minimize, Problem})\n\nReturn the objective.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.objvalue-Tuple{Problem, DualSolution}-api","page":"API reference","title":"ClusteredLowRankSolver.objvalue","text":"objvalue(problem::Problem, sol::DualSolution)\n\nReturn the objective value of the dual solution with respect to the given objective or problem.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.objvalue-Union{Tuple{T}, Tuple{Objective, DualSolution{T}}} where T<:Number-api","page":"API reference","title":"ClusteredLowRankSolver.objvalue","text":"objvalue(objective::Objective, sol::DualSolution)\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.optimal-Tuple{ClusteredLowRankSolver.Status}-api","page":"API reference","title":"ClusteredLowRankSolver.optimal","text":"optimal(x::Status)\n\nReturn whether the solutions corresponding to this status are optimal.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.partial_linearsystem-Tuple{Problem, DualSolution, Vector{Int64}}-api","page":"API reference","title":"ClusteredLowRankSolver.partial_linearsystem","text":"partial_linearsystem(problem::Problem, sol::DualSolution, columns::Union{DualSolution, Vector{Int}})\n\nLet x be the vcat of the vectorizations of the matrix variables. Let I be the index set of the columns. This function returns the matrix AI and vector b-Ax such that the constraints for  the error vector e using variables indexed by I are given by the system AIe = b-Ax.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.sample_points_chebyshev-api","page":"API reference","title":"ClusteredLowRankSolver.sample_points_chebyshev","text":"sample_points_chebyshev(d, a = -1, b = 1; T=BigFloat) -> Vector{T}\n\nGenerate the d+1 Chebyshev points in [a,b].\n\n\n\n\n\n","category":"function"},{"location":"api/#ClusteredLowRankSolver.sample_points_chebyshev_mod-api","page":"API reference","title":"ClusteredLowRankSolver.sample_points_chebyshev_mod","text":"sample_points_chebyshev_mod(d, a = -1, b = 1; T=BigFloat) -> Vector{T}\n\nGenerate the d+1 modified chebyshev points in [a,b], the chebyshev points divided by cos(pi/(2(d+1))).\n\n\n\n\n\n","category":"function"},{"location":"api/#ClusteredLowRankSolver.sample_points_padua-Tuple{Any}-api","page":"API reference","title":"ClusteredLowRankSolver.sample_points_padua","text":"sample_points_padua(d; T=BigFloat) -> Vector{Vector{T}}\n\nGenerate the Padua points for degree d.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.sample_points_rescaled_laguerre-Tuple{Any}-api","page":"API reference","title":"ClusteredLowRankSolver.sample_points_rescaled_laguerre","text":"sample_points_rescaled_laguerre(d; T=BigFloat) -> Vector{T}\n\nGenerate 'rescaled laguerre' points, as in SDPB.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.sample_points_simplex-Tuple{Any, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.sample_points_simplex","text":"sample_points_simplex(n, d; T=BigFloat) -> Vector{Vector{T}}\n\nGenerate the rational sample points in the unit simplex with denominator d.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.sampled_polynomial_ring-Tuple{Any, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.sampled_polynomial_ring","text":"sampled_polynomial_ring(base_ring, samples)\n\nCreate a SampledMPolyRing with values in base_ring defined on samples. The samples should be sorted.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.sdpa_sparse_to_problem-api","page":"API reference","title":"ClusteredLowRankSolver.sdpa_sparse_to_problem","text":"sdpa_sparse_to_problem(filename,obj_shift = 0; T=Float64)\n\nDefine the Problem from the file filename assuming it is in SDPA sparse format, using the number type T. Optionally add an objective shift. \n\n\n\n\n\n","category":"function"},{"location":"api/#ClusteredLowRankSolver.slacks-Tuple{Problem, DualSolution}-api","page":"API reference","title":"ClusteredLowRankSolver.slacks","text":"slacks(problem, dualsol)\n\nCompute the difference between the left hand side and the right hand side of all constraints\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.solvesdp-Tuple{Problem}-api","page":"API reference","title":"ClusteredLowRankSolver.solvesdp","text":"\tsolvesdp(problem::Problem; kwargs...)\n\n    solvesdp(sdp::ClusteredLowRankSDP; kwargs...)\n\nSolve the semidefinite program generated from problem or sdp. \n\nKeyword arguments:\n\nprec (default: precision(BigFloat)): the precision used\ngamma (default: 0.9): the step length reduction; a maximum step length of α reduces to a step length of max(gamma*α,1)\nbeta_(in)feasible (default: 0.1 (0.3)): the amount mu is tried to be reduced by in each iteration, for (in)feasible solutions\nomega_p/d (default: 10^10): the starting matrix variable for the primal/dual is omega_p/d*I\nmaxiterations (default: 500): the maximum number of iterations\nduality_gap_threshold (default: 10^-15): how near to optimal the solution needs to be\nprimal/dual_error_threshold (default:10^-30): how feasible the primal/dual solution needs to be\nmax_complementary_gap (default: 10^100): the maximum of dot(X,Y)/nrows(X) allowed\nneed_primal_feasible/need_dual_feasible (default: false): terminate when the solution is primal/dual feasible\nverbose (default: true): print information after every iteration if true\nstep_length_threshold (default: 10^-7): the minimum step length allowed\nprimalsol (default: nothing): start from the solution (primalsol, dualsol) if both primalsol and dualsol are given\ndualsol (default: nothing): start from the solution (primalsol, dualsol) if both primalsol and dualsol are given\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.to_field-Tuple{Any, Nemo.AbsSimpleNumField, Any}-api","page":"API reference","title":"ClusteredLowRankSolver.to_field","text":"to_field(v, N, g; bits=100, errbound=1e-15)\n\nFind an approximation of v in the number field N, using the approximate generator g of N.\n\n\n\n\n\n","category":"method"},{"location":"api/#ClusteredLowRankSolver.vectorize-Union{Tuple{DualSolution{T}}, Tuple{T}} where T-api","page":"API reference","title":"ClusteredLowRankSolver.vectorize","text":"vectorize(sol)\n\nVectorize the solution by taking the upper triangular part of the matrices.  The variables are first sorted by size and then by hash.\n\n\n\n\n\n","category":"method"},{"location":"examples/sphere_packing/#exspherepacking","page":"Sphere packing","title":"Example: Binary sphere packing","text":"","category":"section"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"This is a slightly more advanced example, which uses the non-diagonal block structure of the constraint matrices. We consider the maximum density which can be obtained by packing spheres with radii r_1 ldots r_N in R^n. In [5] the Cohn-Elkies linear programming bound for sphere packing densities [6] is generalized to N radii. We will follow their approach to define an optimization problem in terms of polynomial equality constraints.","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"compat: Theorem\nLet r_1ldotsr_N0, and let fmathbbR^n to mathbbR^N times N be a matrix-valued function whose every component f_ij is a radial Schwartz function. Suppose f satisfies the following conditions:The matrix big(hatf_ij(0)- (mathrmvol B(r_i))^12(mathrmvol B(r_j))^12big)_ij=1^N is positive semidefinite, where B(r) is the ball of radius r centered at the origin.\nThe matrix of Fourier transforms big(hatf_ij(t)big)_ij=1^N is positive semidefinite for every t0.\nf_ij(w)leq 0 if w geq r_i+r_j, for ij = 1ldotsN.Then the density of any sphere packing of spheres of radii r_1ldotsr_N in the Euclidean space mathbbR^n is at most max f_ii(0) i=1ldotsN","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"Using functions of the form","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"widehatf(x) = sum_k=0^d A_k x^2k e^-pi x^2","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"we obtain by Lemma 5.3 of [5]","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"f(x) = sum_k=0^d A_k frackpi^kL_k^n2-1(pi x^2)e^-pi x^2","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"where A_k are real, symmetric N times N matrices, and L_k^n2-1 is the degree k Laguerre polynomial with parameter n2-1. Since positive factors do not influence positivity, we can ignore the factors e^-pi x^2. We denote the resulting polynomials still by f and hatf, abusing notation. This gives the constraint for first requirement of the Theorem","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"hatf(0) - big((mathrmvol B(r_i))^12(mathrmvol B(r_j))^12big)_ij=1^N = Y_0 succeq 0","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"We can apply this constraint element-wise to get N(N-1)2 constraints enforcing the first requirement.","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"Using the theory of matrix polynomial programs (see, e.g., [2]), we know that the second requirement is fulfilled if and only if there are positive semidefinite matrices Y_1 and Y_2 such that","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"hatf(t)_ij = langle b(t)b(t)^sf T otimes E_ij Y_1 rangle + langle tb(t)b(t)^sf T otimes E_ij Y_2 rangle","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"for every entry hatf_ij, ij=1ldots N.","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"We can enforce the third requirement with the constraints that there are positive semidefinite matrices Z_ij^l for l=12 and ij=1ldotsN such that","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"f(w)_ij + langle b(w)b(w)^sf T Z_ij^1 rangle + langle (w-(r_i+r_j)^2)b(w)b(w)^sf T Z_ij^2 rangle = 0","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"where we denote w = x^2 (note that f(x)_ij is a polynomial in x^2).","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"Finally, the objective can be modelled by introducing a free variable M and requiring that","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"f_ii(0) leq M","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"where we minimize over M. This assures that M = maxf_ii(0), which equals the bound given by f.","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"In the following, we will show how to model the second type of constraint. This constraint contains the internal block structure, which is not present in the previous example of the Delsarte linear programming bound. For this, we assume we defined a certain maximum degree d and the dimension n. We use the packages AbstractAlgebra and ClusteredLowRankSolver. As in the previous example, we first construct a suitable basis and sample points.","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"R, x = polynomial_ring(RealField, :x)\n\nbasis = basis_laguerre(2d+1, BigFloat(n)/2-1, BigFloat(2*pi)*x)\nsamples = sample_points_rescaled_laguerre(2d+1)\nbasis, samples = approximatefekete(basis, samples)","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"Now, for given i != j (over which we normally would loop to get all constraints), we can start defining the corresponding constraint.","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"free_dict = Dict()\nfor k = 0:2d+1\n    free_dict[(k, i, j)] = -x^k\nend\n\npsd_dict = Dict()\n# We need to keep the blocks symmetric,\n# so we distribute the matrices over the two blocks.\npsd_dict[Block(:SOS21, i, j)] = LowRankMatPol([R(1//2)], [basis[1:d+1]])\npsd_dict[Block(:SOS21, j, i)] = LowRankMatPol([R(1//2)], [basis[1:d+1]])\n\npsd_dict[Block(:SOS22, i, j)] = LowRankMatPol([1//2*x], [basis[1:d+1]])\npsd_dict[Block(:SOS22, j, i)] = LowRankMatPol([1//2*x], [basis[1:d+1]])\n\nconstr = Constraint(0, psd_dict, free_dict, samples)","category":"page"},{"location":"examples/sphere_packing/","page":"Sphere packing","title":"Sphere packing","text":"For i = j, the definition is similar, except that we do not need to distribute the constraint matrices over two blocks. See the SpherePacking.jl for the full code.","category":"page"},{"location":"examples/poly_opt/#expolyopt","page":"Symmetric polynomial optimization","title":"Example: Multivariate polynomial optimization using symmetry reduction","text":"","category":"section"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"In this example, we consider minimizing a multivariate polynomial with S_3 symmetries. The example is inspirated by example 7.1 from [7]. See the Examples folder for the file with the code. We consider the polynomial","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"f(xyz) = x^4 + y^4 + z^4 - 4xyz + x + y + z","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"for which we want to find the minimum value f_min = min_xyz f(xyz). Relaxing the problem with a sum-of-squares constraint gives","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"beginaligned\n    max quad M \n    textst quad f - M textis a sum-of-squares\nendaligned","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"Since the polynomial f is invariant under permuting the variables (i.e., the group action of S_3), it is natural to consider only invariant sum-of-squares polynomials. From [7], we know that any sum-of-squares polynomial invariant under the action of S_3 can be written as","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"    langle Y_1 ww^sf T rangle + langle Y_2 Pi_2 otimes ww^sf T rangle + langle Y_3 Pi_3 otimes ww^sf T rangle","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"where w(xyz) is a vector of basis polynomials of the invariant ring Rxyz^S_3 = Rx+y+z xy+yz+xz xyz, and where Pi_2(xyz) = ((x-y)(y-z)(z-x))^2. The matrix Pi_3 is of rank 2 and has the decomposition v_1 v_1^sf T + v_2 v_2^sf T with","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"v_1 = frac1sqrt2beginpmatrix\n    2x-y-z \n    2yz-zx-xy\nendpmatrix quad text and  quad v_2 = sqrtfrac32beginpmatrix\n    y-z \n    zx-xy\nendpmatrix","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"Since we consider sum-of-squares polynomials of a certain degree d, we restrict to the elements of the matrices Pi_i otimes ww^sf T with degree at most lfloor d2 rfloor.","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"To sample this constraint we need a three-variate minimal unisolvent set for invariant polynomials of degree at most d. In this case, one such example are the representatives of the orbits of S_3 of the rational points in the simplex with denominator d, since these points are invariant under S_3 and are minimal unisolvent (see [2]). However, if the polynomial space is more complicated it is unclear what a minimal unisolvent set is. To show one approach on this we instead make a grid of points which unisolvent but not minimal, and we use the approach of [2] through approximatefekete to choose a good subset of these points and a corresponding good basis for w.","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"As for the example of the Delsarte bound, the objective is simply one free variable M with coefficient 1. We also create a function to generate an invariant basis with variables xyz.","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"using ClusteredLowRankSolver, AbstractAlgebra\n\nfunction invariant_basis(x,y,z, d)\n    # create a vector with a precise type\n    v = [(x*y*z)^0]\n    for deg=1:d, j=0:div(deg,3), i=0:div(deg-3j,2)\n        # monomials in the invariant elementary polynomials\n        # ordered by degree\n        push!(v, (x+y+z)^(deg-2i-3j) * (x*y+y*z+z*x)^i * (x*y*z)^j)\n    end\n    return v\nend\n\nfunction min_f(d)\n\n    obj = Objective(0, Dict(), Dict(:M => 1))","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"In this case, we need a three-variate polynomial ring, and a basis of invariant polynomials. We also use approximatefekete to find a subset of the sample points with a good basis.","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"    FF = RealField\n    R, (x,y,z) = polynomial_ring(FF, [:x, :y, :z])\n    # The polynomial f:\n    f =  x^4 + y^4 + z^4 - 4x*y*z + x + y + z\n\n    # An invariant basis up to degree d:\n    basis = invariant_basis(x, y, z, 2d)\n    # For the sum-of-squares polynomials we have to\n    # select elements of the basis based on the degree\n    degrees = [total_degree(p) for p in basis]\n\n    # generate samples and a good basis\n    cheb_points = [vcat(sample_points_chebyshev(2d+k)...) for k=0:2]\n    samples_grid = [[cheb_points[1][i+1], cheb_points[2][j+1], cheb_points[3][k+1]]\n        for i=0:2d for j=0:2d+1 for k=0:2d+2]\n    basis, samples = approximatefekete(basis, samples_grid)","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"Now we will construct the constraint matrices corresponding to the sum-of-squares parts. Although approximatefekete returns a polynomial basis only characterized by the evaluations on the sample points, basic operations on normal polynomials will also work with sampled polynomials.","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"    psd_dict = Dict()\n\n    equivariants = [[[R(1)]], [[(x-y)*(y-z)*(z-x)]], [[(2x-y-z), (2y*z-x*z-x*y)], [(y-z), (x*z-x*y)]]]\n    # The squares of the prefactors, in case we want to define the program over QQ\n    factors = [[1], [1], [1//2, 3//2]]\n    for eqi in eachindex(equivariants)\n        vecs = []\n        for r in eachindex(equivariants[eqi])\n            vec = []\n            for eq in equivariants[eqi][r], (q, qdeg) in zip(basis, degrees)\n                # only add terms for which the diagonal entry is of degree <=2d\n                if 2total_degree(eq) + 2qdeg <= 2d\n                    push!(vec, eq * q)\n                end\n            end\n            if length(vec) > 0\n                push!(vecs, vec)\n            end\n        end\n        # only add variables for the non-empty matrices\n        if length(vecs) > 0\n            psd_dict[(:trivariatesos, eqi)] = LowRankMatPol(factors[eqi], vecs)\n        end\n    end","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"Now we can formulate the constraint and solve the problem:","category":"page"},{"location":"examples/poly_opt/","page":"Symmetric polynomial optimization","title":"Symmetric polynomial optimization","text":"    # the constraint is SOS + M = f\n    constr = Constraint(f, psd_dict, Dict(:M => 1), samples)\n    problem = Problem(Maximize(obj), [constr])\n\n    status, primalsol, dualsol, time, errorcode = solvesdp(problem)\n    return objvalue(problem, dualsol)\nend\n\nmin_f(2)","category":"page"},{"location":"examples/clustering/#exClustering","page":"Clustering","title":"Example: Clustering","text":"","category":"section"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"Here we give a small example in which it is beneficial to use the option as_free to model positive semidefinite variables as free variables. We focus on the constraints. Suppose you want to solve a semidefinite program with the constraint that ","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"beginalign*\n    langle Y A(x) rangle\nendalign*","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"is nonnegative on a union of k semialgebraic sets ","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"beginalign*\n    G_i = x in mathbbR^n  g_ij(x) geq 0 j=1 ldots m_i\nendalign*","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"and suppose that these semialgebraic sets are archimedean, so that we can use Putinar's theorem. Then this translates into k sum-of-squares constraints; one for each semialgebraic set.","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"Assuming that the matrix A is defined before, as well as the polynomials g[i][j], the basis sosbasis[i][j] of the correct degrees and the sample points samples, this gives the code","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"    constraints = []\n    for i=1:k\n        psd_dict = Dict()\n        # this is the same everywhere\n        psd_dict[:Y] = A\n        for j=1:m[i]\n            # this differs per constraint\n            # note that different sum-of-square matrices have different names\n            psd_dict[(:sos,i,j)] = LowRankMatPol([-g[i][j]], [sosbasis[i][j]])\n        end\n        push!(constraints, Constraint(0,psd_dict,Dict(), samples))\n    end","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"Since the positive semidefinite matrix variable Y occurs in every constraint, the corresponding cluster contains k cdot S constraints after sampling, where S is the number of samples. To split this into k clusters of S constraints, we use the function  model_psd_variables_as_free_variables! to model Y as free variables:","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"    problem = Problem(Minimize(obj), constraints)\n    model_psd_variables_as_free_variables!(problem, [:Y])","category":"page"},{"location":"examples/clustering/","page":"Clustering","title":"Clustering","text":"This adds auxilliary free variables X_ij, adds the constraints X_ij = Y_ij, and replaces the Y_ij in the constraints by X_ij. Then the only positive semidefinite variables in the polynomial constraints are the sums-of-squares matrices, which causes each sums-of-squares constraint to be assigned to its own cluster.","category":"page"},{"location":"rounding/#secrounding","page":"Rounding","title":"Rounding numerical solutions to exact optimal solutions","text":"","category":"section"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"In certain situations there are reasons to believe that there is a 'nice' optimal solution. That is, the kernel of every optimal solution can be defined over a number field of low algebraic degree and low bit size. In that case, we can use the rounding procedure from [1] to obtain such a solution from a precise enough solution returned by a semidefinite programming solver. This is implemented in the function exact_solution. ","category":"page"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"See also the following examples:","category":"page"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"A very basic example of minimizing a univariate polynomial\nA more involved example of minimizing a multivariate polynomial\nRounding the Delsarte LP bound ","category":"page"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"exact_solution","category":"page"},{"location":"rounding/#ClusteredLowRankSolver.exact_solution","page":"Rounding","title":"ClusteredLowRankSolver.exact_solution","text":"exact_solution(problem::Problem, primalsol::PrimalSolution, dualsol::DualSolution; transformed=false, FF = QQ, g=1, settings::RoundingSettings=RoundingSettings(), monomial_bases=nothing)\n\nCompute and return an exact solution to the problem, given a primal solution, dual solution and a field FF with approximate generator g. Return (success, exactdualsol) if transformed=false, and (success, pd_transformed_exactsolution, transformations) if transformed=true.\n\n\n\n\n\n","category":"function"},{"location":"rounding/#A-short-introduction-to-the-rounding-procedure","page":"Rounding","title":"A short introduction to the rounding procedure","text":"","category":"section"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"The rounding procedure consists of three steps. First a nice basis for the kernel of the provided solution is found; this defines the optimal face. In the second step, this basis is used as part of a basis transformation, to obtain a smaller semidefinite program where the affine hull of the constraints has a one-to-one correspondence with the original optimal face. The provided solution is also transformed, to obtain a strictly feasible solution of the new semidefinite program. In the last step, we take an approximation of the numerical, transformed solution over the rationals (or a provided number field), and find an exact solution close to it. See [1] for a more detailed description. ","category":"page"},{"location":"rounding/#Settings-for-the-rounding-procedure","page":"Rounding","title":"Settings for the rounding procedure","text":"","category":"section"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"For ease of use, all settings which can be used to tweak the rounding procedure are collected in the RoundingSettings structure.","category":"page"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"RoundingSettings","category":"page"},{"location":"rounding/#ClusteredLowRankSolver.RoundingSettings","page":"Rounding","title":"ClusteredLowRankSolver.RoundingSettings","text":"RoundingSettings(settings...)\n\nSettings for the rounding procedure:\n\nFinding the kernel\nkernel_errbound: (default: 1e-10) the allowed error for the kernel vectors. That is, the maximum entry of Xv is in absolute value at most this\nkernel_round_errbound: (default: 1e-15) the maximum allowed error when rounding the reduced row-echelon form entrywise\nkernel_use_primal: (default: true) use the primal solution to find the kernel vectors  (otherwise, use an SVD of the dual solution)\nkernel_lll: (default: false) if true, use the LLL algorithm to find the nullspace of the kernel. Otherwise, use the reduced row-echelon form to find kernel vectors.\nkernel_bits: (default: 1000) the maximum number of bits to be used in the LLL algorithm (for finding relations or finding the entries of the RREF)\nReducing the kernel vectors\nreduce_kernelvectors: (default: true) apply the reduction step or not\nreduce_kernelvectors_cutoff: (default: 400) do reduction on the full matrix if its size is at most this cutoff. Otherwise do it on a submatrix\nreduce_kernelvectors_stepsize: (default: 200) the number of extra columns to take into account in each iteration of the reduction step\nTransforming the problem and the solution\nunimodular_transform: (default: true) use a unimodular transform obtained in the reduction step\nnormalize_transformation: (default: true) multiply by a diagonal matrix to get an integer transformation for the problem (for problems over QQ)\nFinding an approximate solution in the field\nregularization: (default: 1e-20) use this regularization for solving the extended system\napproximation_decimals: (default: 40) Approximate the numerical solution using this many digits, entrywise\nRounding the solution to the affine space of constraints\nredundancyfactor: (default: 10) take at least this times the number of constraints columns as potential pivots\npseudo: (default: true) use the psuedo inverse for rounding (this may give solutions with larger bitsize than needed)\npseudo_columnfactor: (default: 1.05) For a system of r rows, use r * pseudo_columnfactor number of columns for the pseudo inverse\nextracolumns_linindep: (default: false) if true, take the extra columns linearly independent of each other (otherwise, random columns)\n\n\n\n\n\n","category":"type"},{"location":"rounding/#roundingsettings","page":"Rounding","title":"Finding the right settings","text":"","category":"section"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"Depending on the problem, the default parameters will suffice. In the following cases small changes are needed:","category":"page"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"The kernel vectors are not found correctly, or have significantly higher maximum number after reduction than the maximum numerator and denominator.\nTry to solve to a smaller duality gap, and/or decrease the setting kernel_round_errbound.\nTry the settings kernel_use_primal=false.\nThe final solution does not satisfy the constraints. (Or not enough pivots were found) \nincrease redundancyfactor, or set it to -1 to take all variables into account.\nThis might also be an indication that the kernel vectors are not found correctly (see item 1).\nThe final solution is not positive semidefinite.\nIncrease the setting approximation_decimals. Make sure that the provided solution has at least that many digits correct (the duality gap should be lower than 10^(-approximation_digits))\nIncrease the setting pseudo_columnfactor. The higher this setting, the closer the exact solution will be to the provided solution. However, this also increases the bit size of the exact solution.\nIn some cases this is also an indication that the kernel vectors are not found correctly (see item 1), especially when the reported negative eigenvalues are close to zero.","category":"page"},{"location":"rounding/#Using-coefficient-matching","page":"Rounding","title":"Using coefficient matching","text":"","category":"section"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"Although the semidefinite program used in the solver is defined using sampling, it is possible to use a semidefinite program defined using coefficient matching in a monomial basis for the rounding procedure. This is not yet fully automated; the user needs to provide the monomial basis for each polynomial constraint to the rounding procedure in order to use this. Using coefficient matching instead of sampling in the rounding heuristic generally decreases the size of the exact solutions. See below for an example using the slightly modified code for the Delsarte LP bound in the example for rounding. Here we have one univariate constraint with polynomials up to degree 2d.","category":"page"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"d = 3\nproblem, primalsol, dualsol = delsarte(8, 1//2, d; duality_gap_threshold=1e-30)\nR, (x,) = polynomial_ring(QQ, 1)\nmon_basis = [x^k for k=0:2d]\nsuccess, exactdualsol = exact_solution(problem, primalsol, dualsol, monbases = [mon_basis])","category":"page"},{"location":"rounding/#Finding-the-appropriate-number-field-for-the-rounding-procedure","page":"Rounding","title":"Finding the appropriate number field for the rounding procedure","text":"","category":"section"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"It is in general not directly clear over which  number field the optimal face can be defined. The function find_field can help to find such a field. See Section 2.5 of [1] for an explanation of the procedure.","category":"page"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"find_field","category":"page"},{"location":"rounding/#ClusteredLowRankSolver.find_field","page":"Rounding","title":"ClusteredLowRankSolver.find_field","text":"find_field(primalsol, dualsol, max_degree=4; valbound=1e-15, errbound=1e-15, bits=100, max_coeff=1000)\n\nHeuristically find a field over which the kernel can probably be defined. \n\nOnly consider values at least valbound in absolute value. Find minimal polynomials  such that the chosen entries are approximately generators with an error bound of errbound. Use bits number of bits and reject minimal polynomials with a maximum coefficient of more than max_coeff.\n\n\n\n\n\n","category":"function"},{"location":"rounding/#Getting-an-exact-feasible-solution-close-to-the-optimum","page":"Rounding","title":"Getting an exact feasible solution close to the optimum","text":"","category":"section"},{"location":"rounding/","page":"Rounding","title":"Rounding","text":"In general, the kernel of the optimal solutions can only be defined using a number field of high algebraic degree, or with large bit size. In this case it is unlikely that the exact kernel can be found, so that the rounding procedure will fail. However, it is possible to get an exact feasible solution with objective value close to the optimum using the rounding procedure. To do this, solve the semidefinite program as a feasibility problem (no objective), with the extra constraint that the (original) objective should be a rational number close to the optimum value. Then the solver will return a strictly feasible solution if it exists (that is, with empty kernel). The function exact_solution will now essentially skip the steps of finding the kernel vectors and transforming the problem, since there are no kernel vectors. Therefore, it will find an exact feasible solution close to the provided solution such that the objective of the original problem is equal to the rational number in the extra constraint. See Rounding the Delsarte LP bound for a worked example.","category":"page"},{"location":"examples/rounding/#exrounding","page":"Rounding the Delsarte LP bound","title":"Example: Rounding the Delsarte LP bound","text":"","category":"section"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"For this example, we slightly modify the code of the Delsarte bound to define an exact problem.","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"using ClusteredLowRankSolver, Nemo\n\nfunction delsarte_exact(n, d, costheta; FF=QQ, g=1, eps=1e-40)\n    constraints = []\n\n    P, x = polynomial_ring(FF, :x)\n\n    gbasis = basis_gegenbauer(2d, n, x)\n    sosbasis = basis_chebyshev(2d, x)\n\n    samples = sample_points_chebyshev(2d)\n    # round the samples to QQ:\n    samples = [round(BigInt, x * 10^4)//10^4 for x in samples]\n\n    c = Dict()\n    for k = 0:2d\n        c[k] = [gbasis[k+1];;]\n    end\n    c[:A] = LowRankMatPol([1], [sosbasis[1:d+1]])\n    c[:B] = LowRankMatPol([(x+1)*(costheta-x)], [sosbasis[1:d]])\n    push!(constraints, Constraint(-1, c, Dict(), samples))\n\n    objective = Objective(1, Dict(k => [1;;] for k=0:2d), Dict())\n\n    problem = Problem(Minimize(objective), constraints)\n\n    problem_bigfloat = map(x->generic_embedding(x, g), problem)\n    status, primalsol, dualsol, time, errorcode = solvesdp(problem_bigfloat, duality_gap_threshold=eps)\n\n    return objvalue(problem, dualsol), problem, primalsol, dualsol\nend\nnothing #hide","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"Here we made a few modifications. ","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"We defined the polynomial ring over the field FF, so that the problem becomes exact.\nWe also made the samples exact rational numbers. This is in this case not strictly necessary if we use coefficient matching for the rounding procedure, but it is necessary when evaluating polynomials on these samples.\nWe added the line\n    problem_bigfloat = map(x->generic_embedding(x, g), problem)\nThis embeds the field in mathbbR using the floating point approximation g of the generator of the field we use. The exact problem cannot be solved with the solver if we use a number field with a generator, since it is unclear which generator of the field we meant when building the problem.\nWe now return the problem and the primal and dual solution too. ","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"One example where the delsarte bound is sharp, is when considering a code with costheta = 1(sqrt5 - 1) in mathbbR^4. The optimal spherical code then has 120 points. To round the solution, we first define the field using the minimal polynomial x^2 - 5 = 0.","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"R, x = polynomial_ring(QQ, :x)\nN, z = number_field(x^2 - 5, :z)\ngapprox = sqrt(big(5))\nnothing # hide","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"Then we can call the rounding procedure:","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"n = 4\nd = 9\ncostheta = 1/(z-1)\n# find an approximate solution\nobj, problem, primalsol, dualsol = delsarte_exact(n, d, costheta; FF=N, g = gapprox)\n# round the approximate solution to an exact solution\nsuccess, exactdualsol = exact_solution(problem, primalsol, dualsol; FF=N, g=gapprox)\nobjexact = objvalue(problem, exactdualsol)\n(success, objexact)","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"When the problem is not defined over the same field as the solution, we can find the field using","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"N2, gapprox2 = find_field(primalsol, dualsol)\ndefining_polynomial(N2), gapprox2","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"which returns the field with defining polynomial x^2 + x - 1 = 0 and approximate generator -1618033 approx (-1 -sqrt5)2.","category":"page"},{"location":"examples/rounding/#Using-coefficient-matching","page":"Rounding the Delsarte LP bound","title":"Using coefficient matching","text":"","category":"section"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"As mentioned in the section about Rounding, using coefficient matching will often result in a solution of smaller bit size. To do that in this example, one can use","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"obj, problem, primalsol, dualsol = delsarte_exact(n, d, costheta; FF=N, g = gapprox)\nR, x = polynomial_ring(N, :x)\nmon_basis = [x^k for k=0:2d]\nsuccess, exactdualsol_smaller = exact_solution(problem, primalsol, dualsol, FF=N, g=gapprox, monomial_bases = [mon_basis])\nnothing # show the full output, this time? # hide","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"This is recommended especially for larger polynomial programs.","category":"page"},{"location":"examples/rounding/#Getting-an-exact-feasible-solution-close-to-the-optimum","page":"Rounding the Delsarte LP bound","title":"Getting an exact feasible solution close to the optimum","text":"","category":"section"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"To modify the code to find an exact strictly feasible solution, we change the code for the objective to the following:","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"   if isnothing(obj)\n      objective = Objective(1, Dict(k => [1;;] for k=0:2d), Dict())\n   else\n      objective = Objective(0, Dict(), Dict()) \n      push!(constraints, Constraint(obj-1, Dict(k => [1;;] for k=0:2d), Dict()))\n   end","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"where the function signature is now given by","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"function delsarte_exact(n, d, costheta; obj=nothing, FF=QQ, g=1, eps=1e-40)","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"That is, it takes an extra argument obj. When obj is set to a numerical value, this adds the constraint that the objective should be equal to obj. Then the exact solution can be found as follows.","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"using ClusteredLowRankSolver, Nemo\n\nfunction delsarte_exact(n, d, costheta; obj=nothing, FF=QQ, g=1, eps=1e-40)\n    constraints = []\n\n    P, x = polynomial_ring(FF, :x)\n\n    gbasis = basis_gegenbauer(2d, n, x)\n    sosbasis = basis_chebyshev(2d, x)\n\n    samples = sample_points_chebyshev(2d)\n    # round the samples to QQ:\n    samples = [round(BigInt, x * 10^4)//10^4 for x in samples]\n\n    c = Dict()\n    for k = 0:2d\n        c[k] = [gbasis[k+1];;]\n    end\n    c[:A] = LowRankMatPol([1], [sosbasis[1:d+1]])\n    c[:B] = LowRankMatPol([(x+1)*(costheta-x)], [sosbasis[1:d]])\n    push!(constraints, Constraint(-1, c, Dict(), samples))\n\n    if isnothing(obj)\n        objective = Objective(1, Dict(k => [1;;] for k=0:2d), Dict())\n    else\n        objective = Objective(0, Dict(), Dict()) \n        push!(constraints, Constraint(obj-1, Dict(k => [1;;] for k=0:2d), Dict()))\n    end\n\n    problem = Problem(Minimize(objective), constraints)\n\n    problem_bigfloat = map(x->generic_embedding(x, g), problem)\n    status, primalsol, dualsol, time, errorcode = solvesdp(problem_bigfloat, duality_gap_threshold=eps)\n\n    return objvalue(problem, dualsol), problem, primalsol, dualsol\nend","category":"page"},{"location":"examples/rounding/","page":"Rounding the Delsarte LP bound","title":"Rounding the Delsarte LP bound","text":"d = 10\n# find the objective\nobj_initial, problem_initial, _, _ = delsarte_exact(3, d, 1//2)\n# find a strictly feasible solution with a slightly larger objective\nobj = obj_initial + 1e-6\n_, problem, primalsol, dualsol = delsarte_exact(3, d, 1//2, obj=rationalize(obj))\n# round the solution\nsuccessfull, exactdualsol = exact_solution(problem, primalsol, dualsol)\nFloat64(objvalue(problem_initial, exactdualsol)), obj_initial","category":"page"},{"location":"solving/#solver","page":"Solving","title":"The solver","text":"","category":"section"},{"location":"solving/","page":"Solving","title":"Solving","text":"ClusteredLowRankSolver.jl implements a primal-dual interior-point method. That is, it solves both the primal and the dual problem. The problem given to the solver is considered to be in dual form. For more information on the primal-dual algorithm, see [2] and [3].","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"A Problem can be solved using the function solvesdp. This first converts the problem to a ClusteredLowRankSDP, after which it is solved using the algorithm.","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"solvesdp","category":"page"},{"location":"solving/#ClusteredLowRankSolver.solvesdp","page":"Solving","title":"ClusteredLowRankSolver.solvesdp","text":"\tsolvesdp(problem::Problem; kwargs...)\n\n    solvesdp(sdp::ClusteredLowRankSDP; kwargs...)\n\nSolve the semidefinite program generated from problem or sdp. \n\nKeyword arguments:\n\nprec (default: precision(BigFloat)): the precision used\ngamma (default: 0.9): the step length reduction; a maximum step length of α reduces to a step length of max(gamma*α,1)\nbeta_(in)feasible (default: 0.1 (0.3)): the amount mu is tried to be reduced by in each iteration, for (in)feasible solutions\nomega_p/d (default: 10^10): the starting matrix variable for the primal/dual is omega_p/d*I\nmaxiterations (default: 500): the maximum number of iterations\nduality_gap_threshold (default: 10^-15): how near to optimal the solution needs to be\nprimal/dual_error_threshold (default:10^-30): how feasible the primal/dual solution needs to be\nmax_complementary_gap (default: 10^100): the maximum of dot(X,Y)/nrows(X) allowed\nneed_primal_feasible/need_dual_feasible (default: false): terminate when the solution is primal/dual feasible\nverbose (default: true): print information after every iteration if true\nstep_length_threshold (default: 10^-7): the minimum step length allowed\nprimalsol (default: nothing): start from the solution (primalsol, dualsol) if both primalsol and dualsol are given\ndualsol (default: nothing): start from the solution (primalsol, dualsol) if both primalsol and dualsol are given\n\n\n\n\n\n","category":"function"},{"location":"solving/#Options","page":"Solving","title":"Options","text":"","category":"section"},{"location":"solving/","page":"Solving","title":"Solving","text":"Here we list the most important options. For the remaining options, see the documentation and the explanation of the algorithm in [3].","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"prec - The number of bits used for the calculations. The default is the BigFloat precision, which defaults to 256 bits.\nduality_gap_threshold - Gives an indication of how close the solution is to the optimal solution. As a rule of thumb, a duality gap of 10^-(k+1) gives k correct digits.  Default: 10^-15\ngamma - The step length reduction; if a step of alpha is possible, a step of min(gamma alpha 1) is taken. A lower gamma results in a more stable convergence, but can be significantly slower. Default: 09.\nomega_p, omega_d - The size of the initial primal respectively dual solution. A low omega can keep the solver from converging, but a high omega in general increases the number of iterations needed and thus also the solving time. Default: 10^10\nneed_primal_feasible, need_dual_feasible - If true, terminate when a primal or dual feasible solution is found, respectively. Default: false.\nprimal_error_threshold, dual_error_threshold - The threshold below which the primal and dual error should be to be considered primal and dual feasible, respectively. Default: 10^-15.","category":"page"},{"location":"solving/#Output","page":"Solving","title":"Output","text":"","category":"section"},{"location":"solving/","page":"Solving","title":"Solving","text":"When the option verbose is true (default), the solver will output information for every iteration. In order of output, we have (where the values are from the start of the iteration except for the step lengths, which are only known at the end of the iteration)","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"The iteration number\nThe time since the start of the first iteration\nThe complementary gap mu = langle X Y rangle  K where K is the number of rows of X. Here X and Y denote the primal and dual solution matrices. The solution will converge to the optimum for mu to 0.\nThe primal objective\nThe dual objective\nThe relative duality gap \nThe primal matrix error \nThe primal scalar error \nThe dual (scalar) error \nThe primal step length\nThe dual step length\nbeta_c. The solver tries to reduce mu by this factor in this iteration.","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"An example of the output of the Example from polynomial optimization is","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"iter  time(s)           μ       P-obj       D-obj        gap    P-error    p-error    d-error        α_p        α_d       beta\n    1     11.9   1.000e+20   0.000e+00   0.000e+00   0.00e+00   1.00e+10   1.00e+00   1.95e+10   7.42e-01   7.10e-01   3.00e-01\n    2     13.4   3.995e+19   1.999e+11  -2.907e+09   1.03e+00   2.58e+09   2.58e-01   5.65e+09   7.46e-01   7.17e-01   3.00e-01\n    3     13.4   1.576e+19   3.079e+11  -4.779e+09   1.03e+00   6.53e+08   6.53e-02   1.60e+09   7.32e-01   7.31e-01   3.00e-01\n...\n   55     13.9   5.066e-14  -2.113e+00  -2.113e+00   8.39e-14   8.64e-78   2.59e-77   8.21e-73   1.00e+00   1.00e+00   1.00e-01\n   56     13.9   5.067e-15  -2.113e+00  -2.113e+00   8.39e-15   8.64e-78   8.64e-78   8.39e-73   1.00e+00   1.00e+00   1.00e-01\nOptimal solution found\n 13.860834 seconds (13.74 M allocations: 913.073 MiB, 7.72% gc time, 93.09% compilation time)\n iter  time(s)           μ       P-obj       D-obj        gap    P-error    p-error    d-error        α_p        α_d       beta\n\nPrimal objective:-2.112913881423601867325289796075301826150007716044362101360781221096092533872562\nDual objective:-2.112913881423605414349991239275382883067580432169230529548206052006356176913883\nDuality gap:8.393680245626824434313082297089851809408852609517159688543365552836941907249006e-16","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"Note that the first iteration takes long because the functions used by the solver get compiled. The function solvesdp returns the status of the solutions, the primal and dual solutions, the solve time and an error code (see below).","category":"page"},{"location":"solving/#Status","page":"Solving","title":"Status","text":"","category":"section"},{"location":"solving/","page":"Solving","title":"Solving","text":"When the algorithm finishes due to one of the termination criteria, the status, the final solution together with the objectives, the used time and an error code is returned. The status can be one of","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"Optimal\nNearOptimal -  The solution is primal and dual feasible, and the duality gap is small (10^-8), although not smaller than duality_gap_threshold.\nFeasible\nPrimalFeasible or DualFeasible\nNotConverged","category":"page"},{"location":"solving/#Errors","page":"Solving","title":"Errors","text":"","category":"section"},{"location":"solving/","page":"Solving","title":"Solving","text":"Although unwanted, errors can be part of the output as well. The error codes give an indication what a possible solution could be to avoid the errors.","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"No error\nAn arbitrary error. This can be an internal error such as a decomposition that was unsuccessful. If this occurs in the first iteration, it is a strong indication that the constraints are linearly dependent, e.g. due to using a set of sample points which is not minimal unisolvent for the basis used. Otherwise increasing the precision may help. This also includes errors which are due to external factors such as a keyboard interrupt.\nThe maximum number of iterations has been exceeded. Reasons include: slow convergence, a difficult problem. Possible solutions: increase the maximum number of iterations, increase gamma (if gamma is small), change the starting solution (omega_p and omega_d).\nThe maximum complementary gap (mu) has been exceeded. Usually this indicates (primal and/or dual) infeasibility.\nThe step length is below the step length threshold. This indicates precision errors or a difficult problem. This may be solved by increasing the initial solutions (omega_p and omega_d), or by decreasing the step length reduction gamma, or by increasing the precision prec. If additionally the complementary gap is increasing, it might indicate (primal and/or dual) infeasibility.","category":"page"},{"location":"solving/#Multithreading","page":"Solving","title":"Multithreading","text":"","category":"section"},{"location":"solving/","page":"Solving","title":"Solving","text":"The solver supports multithreading. This can be used by starting julia with","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"julia -t n","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"where n denotes the number of threads.","category":"page"},{"location":"solving/","page":"Solving","title":"Solving","text":"warning: Warning\nOn Windows, using multiple threads can lead to errors when using multiple clusters and free variables. This is probably related to Arb or the Julia interface to Arb.","category":"page"},{"location":"#ClusteredLowRankSolver.jl","page":"Home","title":"ClusteredLowRankSolver.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ClusteredLowRankSolver.jl implements ","category":"page"},{"location":"","page":"Home","title":"Home","text":"a primal-dual interior point method for solving semidefinite programming problems;\na minimal interface to model semidefinite programming problems with (optional) polynomial equality constraints; \nfunctionality for working with sampled polynomials; and\nan implementation of a rounding heuristic which can round the numerical output of the solver to an exact optimal solution over rational or algebraic numbers. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The solver can exploit the low-rank structure of constraint matrices (which arise naturally from enforcing polynomial identities by evaluating both sides at a unisolvent set) but can also work with dense constraint matrices. The solver uses arb for high-precision numerics and the interface integrates with the Nemo computer algebra system.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The solver is written in Julia, and has been registered as a Julia package. Typing using ClusteredLowRankSolver in the REPL will prompt installation if the package has not been installed yet.","category":"page"},{"location":"#Examples","page":"Home","title":"Examples","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here we give two small examples to showcase the interface. For more explanation on the interface, see the Tutorial. ","category":"page"},{"location":"#Example-1:-The-Goemans-Williamson-MAX-CUT-relaxation","page":"Home","title":"Example 1: The Goemans-Williamson MAX-CUT relaxation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Given a Laplacian L of a graph with n vertices, the semidefinite programming relaxation of the max-cut problem reads","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\n textmaximize   leftlangle frac14L X rightrangle\n textsubject to   langle E_ii X rangle = 1  i=1ldotsn\nX in S_+^n\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"where E_ii is the matrix with a one in the (ii) entry, and zeros elsewhere. Here langle cdot cdot rangle denotes the trace inner product.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The following code implements this using ClusteredLowRankSolver.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using ClusteredLowRankSolver\n\nfunction goemans_williamson(L::Matrix; eps=1e-40)\n    n = size(L, 1)\n\n    # Construct the objective\n    obj = Objective(0, Dict(:X => 1//4 * L), Dict())\n\n    # Construct the constraints\n    constraints = []\n    for i = 1:n\n        M = zeros(Rational{BigInt}, n, n)\n        M[i, i] = 1//1\n        # the first argument is the right hand side\n        push!(constraints, Constraint(1, Dict(:X => M), Dict()))\n    end\n\n    # Construct the problem: Maximize the objective s.t. the constraints hold\n    problem = Problem(Maximize(obj), constraints)\n\n    # Solve the problem\n    status, primalsol, dualsol, time, errorcode = solvesdp(problem, duality_gap_threshold=eps)\n\n    objvalue(problem, dualsol), matrixvar(dualsol, :X)\nend\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"For a three-cycle, this gives","category":"page"},{"location":"","page":"Home","title":"Home","text":"L = [2 -1 -1; -1 2 -1; -1 -1 2]\nobj, X = goemans_williamson(L)\nobj","category":"page"},{"location":"#Example-2:-Finding-the-global-minimum-of-a-univariate-polynomial","page":"Home","title":"Example 2: Finding the global minimum of a univariate polynomial","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To find the minimum of a polynomial f of degree 2d, one can use the following problem","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\n textmaximize   lambda\n textsubject to   f - lambda = s\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"where s is a sum-of-squares polynomial of degree 2d. Let m be a vector whose entries form a basis of the polynomials up to degree d, then we can write s = langle m(x)m(x)^T X rangle, where X is a positive semidefinite matrix.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using ClusteredLowRankSolver, Nemo\n\nfunction polyopt(f, d)\n    # Set up the polynomial ring \n    P = parent(f)\n    u = gen(P)\n\n    # Compute the polynomial basis and the samples\n    sosbasis = basis_chebyshev(d, u)\n    samples = sample_points_chebyshev(2d, -1, 1) \n\n    # Construct the constraint SOS + lambda = f\n    c = Dict()\n    c[:X] = LowRankMatPol([1], [sosbasis[1:d+1]])\n    constraint = Constraint(f, c, Dict(:lambda => 1), samples)\n\n    # Construct the objective\n    objective = Objective(0, Dict(), Dict(:lambda => 1))\n\n    # Construct the SOS problem: minimize the objective s.t. the constraint holds\n    problem = Problem(Maximize(objective), [constraint])\n\n    #Solve the SDP and return results\n    status, primalsol, dualsol, time, errorcode = solvesdp(problem)    \n    \n    objvalue(problem, dualsol)\nend\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then we can for example find the minimum of the polynomial x^2+1 using","category":"page"},{"location":"","page":"Home","title":"Home","text":"R, x = polynomial_ring(QQ, :x)\nminvalue = polyopt(x^2+1, 1)","category":"page"},{"location":"#rounding_univariate","page":"Home","title":"Exact version of Example 2","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To find the minimum exactly we can use the following function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using ClusteredLowRankSolver, Nemo\n\nfunction polyopt_exact(f, d)\n    # Set up the polynomial ring \n    P = parent(f)\n    u = gen(P)\n\n    # Compute the polynomial basis and the samples\n    sosbasis = basis_chebyshev(d, u)\n    samples = [round(BigInt, 10000x)//10000 for x in sample_points_chebyshev(2d, -1, 1)] \n\n    # Construct the constraint SOS + lambda = f\n    c = Dict()\n    c[:X] = LowRankMatPol([1], [sosbasis[1:d+1]])\n    constraint = Constraint(f, c, Dict(:lambda => 1), samples)\n\n    # Construct the objective\n    objective = Objective(0, Dict(), Dict(:lambda => 1))\n\n    # Construct the SOS problem: minimize the objective s.t. the constraint holds\n    problem = Problem(Maximize(objective), [constraint])\n\n    #Solve the SDP and return results\n    status, primalsol, dualsol, time, errorcode = solvesdp(problem)    \n    \n    success, esol = exact_solution(problem, primalsol, dualsol)\n\n    success, objvalue(problem, esol)\nend\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then we can find the exact minimum of the polynomial x^2+1 using","category":"page"},{"location":"","page":"Home","title":"Home","text":"R, x = polynomial_ring(QQ, :x)\npolyopt_exact(x^2+1, 1)","category":"page"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In this tutorial you will learn","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"to build a Problem, which includes\ncreating the objective\ncreating a constraint\ncombining them into a Problem\nto solve a Problem\nto find an exact optimal solution","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For explanation on more intricate parts of the interface, see Advanced modeling; for additional examples see the Examples section.","category":"page"},{"location":"tutorial/#Running-example","page":"Tutorial","title":"Running example","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We will explain the interface using an example from polynomial optimization. Suppose we want to find the global minimum (or a lower bound on this) of the polynomial","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"f(uvtw) = -ut^3+4vt^2w + 4 utw^2 + 2vw^3 + 4  ut+ 4t^2 -10 vw - 10  w^2 +2","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"in the domain -12 12^4.  We can relax the problem using a sum-of-squares characterization:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"beginaligned\n    textmaximize quad  M  \n    textsubject to quad  f-M  = s_0 + sum_i w_i s_i \nendaligned","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"where the w_i are polynomial weights describing the domain and s_i are sum-of-squares polynomials. In this example we use","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"beginaligned\n    -12 12^4 = (uvtw) p(u) p(v) p(t) p(w) geq 0\nendaligned","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"with p(x) = 14 - x^2. Given a vector m whose entries form a basis of the space of polynomials up to degree d, we can parametrize a sum-of-squares polynomial s of degree 2d by a positive semidefinite matrix Y with","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    s =  Y mm^sf T ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The problem parameters are now ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"the polynomial f\nthe weight polynomials w_i\nthe degree of the relaxation d","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We will start with building a function that takes these parameters, and constructs the Problem. Since the user will give the polynomial f and the weights, we need to extract the polynomial ring and the polynomial variables.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using ClusteredLowRankSolver, Nemo\nfunction min_f(f, ws, d; basis_change=true)\n    # extract the polynomial ring\n    R = parent(f)\n    x = gens(R)\n    n = nvars(R)","category":"page"},{"location":"tutorial/#Defining-the-objective","page":"Tutorial","title":"Defining the objective","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"First we will define the Objective. This consists of a constant offset, a dictionary with the coefficient matrices for the positive semidefinite matrix variables appearing in the objective, and a dictionary with the scalar coefficients for the free variables used in the objective. In this example, ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"the constant offset is 0, \nthe dictionary of matrix coefficients is empty because we do not use the matrix variables in the objective,\nand the dictionary of scalar coefficients has one entry corresponding to M ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This gives the first part of our function:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    # Define the objective\n    obj = Objective(0, Dict(), Dict(:M => 1))","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Objective","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.Objective","page":"Tutorial","title":"ClusteredLowRankSolver.Objective","text":"Objective(constant, matrixcoeff::Dict, freecoeff::Dict)\n\nThe objective for the Problem.\n\nArguments:\n\nconstant: A constant offset of the objective value.\nmatrixcoeff: A Dict with positive semidefinite matrix variable names as keys and the objective matrices as values.\nfreecoeff: A Dict with free variable names as keys and the coefficients as values.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Defining-the-constraints","page":"Tutorial","title":"Defining the constraints","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Now we will define the constraints. In ClusteredLowRankSolver a Constraint is of the form","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    sum_i langle A_i Y_i rangle + sum_j b_j y_j = c ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To define it, we need the right-hand side c, the matrix coefficients A_i for the positive semidefinite matrix variables, and the coefficients b_j for the free variables. Here the scalars c and b_j and the entries of A_i can either be constants or polynomials. When these are polynomials, we also need a unisolvent set of samples. In this example, ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"the right-hand side c is the polynomial f, \nthe matrix coefficients A_i are the weight polynomials times a suitable low rank matrix of the form mm^sf T, \nand we have one free variable M, with coefficient 1.","category":"page"},{"location":"tutorial/#Defining-the-polynomial-basis-and-the-samples","page":"Tutorial","title":"Defining the polynomial basis and the samples","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We will first define the vector m of basis polynomials, and the samples. For simplicity we will use the monomial basis, and the samples defined by the rational points in the simplex with denominator 2d. ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    basis = basis_monomial(2d, x...)\n    samples = sample_points_simplex(n, 2d; T=Rational{BigInt})","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"See Sampling for more explanation on sampling and unisolvence. In more complicated situations, we can improve the basis with approximatefekete. This orthogonalizes the basis with respect to the sample points, and if samples contains more samples than needed, this selects a good subset of the samples. We include this in the function using a keyword argument basis_change=true and","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    if basis_change\n        basis, samples = approximatefekete(basis, samples)\n    end","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This returns a basis of SampledMPolyRingElem's, which we can only evaluate at samples from samples. Common operations such as multiplications and additions work with these sampled polynomials, but operations such as extracting the degree is not possible since that requires expressing the polynomials in a graded basis. However, if the initial basis is ordered on degree, the final basis will have the same ordering, so we store the degrees using the code","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    degrees = total_degree.(basis_monomial(2d, x...))","category":"page"},{"location":"tutorial/#Defining-the-coefficients-for-the-constraint","page":"Tutorial","title":"Defining the coefficients for the constraint","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Now we are ready to define the low-rank matrix coefficients for the sum of squares polynomials.  For each weight polynomial, we need to add the matrix coefficient corresponding to that weight to the dictionary of matrix coefficients. Since we want polynomials of degree 2d, we first need to select the part of the basis that we use in the sum-of-squares polynomials.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    psd_dict = Dict()\n    for (i, w) in enumerate(ws)\n        basispart = [basis[j] for j in eachindex(basis) if 2degrees[j] + total_degree(w) <= 2d]\n        psd_dict[(:sos, i)] = LowRankMatPol([w], [basispart])\n    end","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The size of the matrices is implicitely given by the size of the LowRankMatPol, which is defined by the prefactors and the rank one terms.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Similarly, we can create the dictionary with the free variables using ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    free_dict = Dict(:M => 1)","category":"page"},{"location":"tutorial/#Defining-the-constraint","page":"Tutorial","title":"Defining the constraint","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Now we can construct the Constraint with","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    con = Constraint(f, psd_dict, free_dict, samples)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"From the constraint, the dictionaries and coefficients can be retrieved using matrixcoeff(s) and freecoeffs.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Specifying non-polynomial constraints works similarly, in which case no samples should be supplied to the Constraint struct.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Constraint\nLowRankMatPol\napproximatefekete\nmatrixcoeff\nmatrixcoeffs\nfreecoeff\nfreecoeffs","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.Constraint","page":"Tutorial","title":"ClusteredLowRankSolver.Constraint","text":"Constraint(constant, matrixcoeff, freecoeff[, samples, scalings])\n\nModels a polynomial constaint of the form\n\n    _i  A_i(x) Y_i   + _j b_j(x) y_j = c(x)\n\nusing sampling on samples. Here the samples are only required if A_i, b_j, and c are polynomials. When the coefficient matrix A_i has block structure with equal sized blocks, the Block struct can be used as key to indicate to which subblock the given matrix corresponds.\n\nArguments:\n\nconstant: The right hand side c(x)\nmatrixcoeff::Dict: The coefficient matrices for the positive semidefinite matrix variables.\nfreecoeff::Dict: The coefficients for the free variables.\nsamples::Vector: The sample set on which the constraint should be satisfied. Required for polynomial constraints.\nscalings::Vector: Optional; scale the constraint with a factor depending on the sample index.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#ClusteredLowRankSolver.LowRankMatPol","page":"Tutorial","title":"ClusteredLowRankSolver.LowRankMatPol","text":"LowRankMatPol(lambda::Vector, vs::Vector{Vector}[, ws::Vector{Vector}])\n\nThe matrix _i λ_i v_i w_i^sf T where v_i are the entries of vs and w_i the entries of ws\n\nIf ws is not specified, use ws = vs.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#ClusteredLowRankSolver.approximatefekete","page":"Tutorial","title":"ClusteredLowRankSolver.approximatefekete","text":"approximatefekete(basis, samples; base_ring=BigFloat) -> basis, samples\n\nCompute approximate fekete points based on samples and a corresponding orthogonal basis. The basis consists of sampled polynomials, sampled at samples.\n\nThis preserves a degree ordering of basis if present.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.matrixcoeff","page":"Tutorial","title":"ClusteredLowRankSolver.matrixcoeff","text":"matrixcoeff(x::Union{Constraint, Objective}, name)\n\nReturn the matrix coefficient corresponding to name\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.matrixcoeffs","page":"Tutorial","title":"ClusteredLowRankSolver.matrixcoeffs","text":"matrixcoeffs(x::Union{Constraint, Objective})\n\nReturn the dictionary of matrix coefficients\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.freecoeff","page":"Tutorial","title":"ClusteredLowRankSolver.freecoeff","text":"freecoeff(x::Union{Constraint, Objective}, name)\n\nReturn the coefficient of the free variable corresponding to name\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.freecoeffs","page":"Tutorial","title":"ClusteredLowRankSolver.freecoeffs","text":"freecoeffs(x::Union{Constraint, Objective})\n\nReturn the dictionary of coefficients for the free variables\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#Defining-the-problem","page":"Tutorial","title":"Defining the problem","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Now that we have the objective and the constraint, we can create the Problem with","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    problem = Problem(Maximize(obj), [con])","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Here the first argument gives the objective and the optimization sense (maximization or minimization). The second argument is a vector of the constraints defining the feasible region (in this example, only the constraint con). The objective and constraints can be retrieved from the problem using objective and constraints. Instead of first constructing all constraints and then defining the Problem, it is also possible to first define the problem using the objective, and then add the constraints with the function addconstraint!","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Problem\nMaximize\nMinimize\nobjective\nconstraints\naddconstraint!","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.Problem","page":"Tutorial","title":"ClusteredLowRankSolver.Problem","text":"    Problem(maximize::Bool, objective::Objective, constraints::Vector{Constraint})\n\n    Problem(obj::Union{Maximize, Minimize}, constraints::Vector)\n\nCombine the objective and constraints into a low-rank polynomial problem.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#ClusteredLowRankSolver.Maximize","page":"Tutorial","title":"ClusteredLowRankSolver.Maximize","text":"Maximize(obj)\n\nMaximize the objective\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#ClusteredLowRankSolver.Minimize","page":"Tutorial","title":"ClusteredLowRankSolver.Minimize","text":"Minimize(obj)\n\nMinimize the objective\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#ClusteredLowRankSolver.objective","page":"Tutorial","title":"ClusteredLowRankSolver.objective","text":"objective(x::Union{Maximize, Minimize, Problem})\n\nReturn the objective.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.constraints","page":"Tutorial","title":"ClusteredLowRankSolver.constraints","text":"constraints(problem::Problem)\n\nReturn the constraints of problem.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.addconstraint!","page":"Tutorial","title":"ClusteredLowRankSolver.addconstraint!","text":"addconstraint!(problem, constraint)\n\nAdd constraint to the constraints of problem. \n\n\n\n\n\n","category":"function"},{"location":"tutorial/#Checking-for-obvious-mistakes","page":"Tutorial","title":"Checking for obvious mistakes","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Some basic checks on the problem and/or semidefinite program can be done using check_problem and check_sdp!. The check_problem function checks that","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"the sizes of the vectors in the low-rank constraint matrices are the same,\nall constraints use at least one positive semidefinite matrix variable,\nall variables in the objective are actually used in the constraints.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The check_sdp! function ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"checks that the constraint matrices are symmetric,\nremoves empty matrices and zero matrices.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    @assert check_problem(problem)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"check_problem\ncheck_sdp!","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.check_problem","page":"Tutorial","title":"ClusteredLowRankSolver.check_problem","text":"check_problem(problem::LowRankPolProblem)\n\nCheck for obvious mistakes in the constraints and objective\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.check_sdp!","page":"Tutorial","title":"ClusteredLowRankSolver.check_sdp!","text":"check_sdp!(sdp::ClusteredLowRankSDP)\n\nCheck whether the constraint matrices are symmetric, and remove empty constraint matrices.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#Solving-the-problem","page":"Tutorial","title":"Solving the problem","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We can solve the Problem with the function solvesdp:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    status, primalsol, dualsol, time, errorcode = solvesdp(problem; prec=512, duality_gap_threshold=1e-60)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This function has multiple options including for example the number of bits used for solving the semidefinite program (prec) and how close the solution should be to optimality (duality_gap_threshold); see the page about the solver for more information.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Alternatively, it is possible to explicitely convert the problem into a semidefinite program using","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    sdp = ClusteredLowRankSDP(problem)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"which can also be solved with","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    status, sol, time, errorcode = solvesdp(sdp)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This is for example useful when you wish to save the semidefinite program (e.g., using Serialization), or when you want to perform the extra checks provided by check_sdp!.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"solvesdp","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.solvesdp-tutorial","page":"Tutorial","title":"ClusteredLowRankSolver.solvesdp","text":"\tsolvesdp(problem::Problem; kwargs...)\n\n    solvesdp(sdp::ClusteredLowRankSDP; kwargs...)\n\nSolve the semidefinite program generated from problem or sdp. \n\nKeyword arguments:\n\nprec (default: precision(BigFloat)): the precision used\ngamma (default: 0.9): the step length reduction; a maximum step length of α reduces to a step length of max(gamma*α,1)\nbeta_(in)feasible (default: 0.1 (0.3)): the amount mu is tried to be reduced by in each iteration, for (in)feasible solutions\nomega_p/d (default: 10^10): the starting matrix variable for the primal/dual is omega_p/d*I\nmaxiterations (default: 500): the maximum number of iterations\nduality_gap_threshold (default: 10^-15): how near to optimal the solution needs to be\nprimal/dual_error_threshold (default:10^-30): how feasible the primal/dual solution needs to be\nmax_complementary_gap (default: 10^100): the maximum of dot(X,Y)/nrows(X) allowed\nneed_primal_feasible/need_dual_feasible (default: false): terminate when the solution is primal/dual feasible\nverbose (default: true): print information after every iteration if true\nstep_length_threshold (default: 10^-7): the minimum step length allowed\nprimalsol (default: nothing): start from the solution (primalsol, dualsol) if both primalsol and dualsol are given\ndualsol (default: nothing): start from the solution (primalsol, dualsol) if both primalsol and dualsol are given\n\n\n\n\n\n","category":"function"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"ClusteredLowRankSDP","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.ClusteredLowRankSDP","page":"Tutorial","title":"ClusteredLowRankSolver.ClusteredLowRankSDP","text":"ClusteredLowRankSDP(problem::Problem; prec=precision(BigFloat), verbose=false)\n\nDefine a ClusteredLowRankSDP based on problem.\n\nKeyword arguments:\n\nprec (default: precision(BigFloat)): the precision of the result\nverbose (default: false): print progress to the standard output\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Retrieving-variables-from-the-solution","page":"Tutorial","title":"Retrieving variables from the solution","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The solver returns, among others, the primal and dual solutions as PrimalSolution{BigFloat} and DualSolution{BigFloat}. To retrieve the variables, it is possible to use","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    matrixvar(dualsol, (:sos, 1))","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"and freevar(dualsol, :M) for free variables. Similarly, use matrixvars and freevars to iterate over all variables:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    for (k, m) in matrixvars(dualsol)\n        # do stuff with the matrix m or the name k\n    end ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To compute the objective for this solution, we can use","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    objective = objvalue(problem, dualsol)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We might also want to return the problem and the solutions:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"    return objective, problem, primalsol, dualsol\nend\nnothing # hide","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"PrimalSolution\nDualSolution\nmatrixvar\nmatrixvars\nfreevar\nfreevars\nobjvalue","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.PrimalSolution","page":"Tutorial","title":"ClusteredLowRankSolver.PrimalSolution","text":"PrimalSolution{T}\n\nA primal solution to the semidefinite program, with fields\n\nbase_ring\nx::Vector{T}\nmatrixvars::Dict{Any, Matrix{T}}\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#ClusteredLowRankSolver.DualSolution","page":"Tutorial","title":"ClusteredLowRankSolver.DualSolution","text":"DualSolution{T}\n\nA dual solution to the semidefinite program, with fields\n\nbase_ring\nmatrixvars::Dict{Any, Matrix{T}}\nfreevars::Dict{Any, T}\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#ClusteredLowRankSolver.matrixvar","page":"Tutorial","title":"ClusteredLowRankSolver.matrixvar","text":"matrixvar(sol, name)\n\nReturn the matrix variable corresponding to name\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.matrixvars","page":"Tutorial","title":"ClusteredLowRankSolver.matrixvars","text":"matrixvars(sol)\n\nReturn the dictionary of matrix variables\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.freevar","page":"Tutorial","title":"ClusteredLowRankSolver.freevar","text":"freevar(sol, name)\n\nReturn the free variable corresponding to name\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.freevars","page":"Tutorial","title":"ClusteredLowRankSolver.freevars","text":"freevars(sol)\n\nReturn the dictionary of the free variables\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.objvalue","page":"Tutorial","title":"ClusteredLowRankSolver.objvalue","text":"objvalue(objective::Objective, sol::DualSolution)\n\n\n\n\n\nobjvalue(problem::Problem, sol::DualSolution)\n\nReturn the objective value of the dual solution with respect to the given objective or problem.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#Running-the-example","page":"Tutorial","title":"Running the example","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Now we can define the problem parameters and run the function","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"d = 2\nR, (u,v,t,w) = polynomial_ring(QQ, 4)\nf = -u*t^3 + 4v*t^2*w + 4u*t*w^2 + 2v*w^3 + 4u*t+ 4t^2 - 10v*w - 10w^2 +2\n# the function for the weights\np(x) = 1//4 - x^2\nws = [R(1), p(u), p(v), p(t), p(w)]\n# call the function\nobj, problem, primalsol, dualsol = min_f(f, ws, d)\nobj","category":"page"},{"location":"tutorial/#Rounding-the-solution","page":"Tutorial","title":"Rounding the solution","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Here we explain how we can heuristically extract an exact optimal solution from the numerical solution. This approach has been developed in the paper [1], and we refer to this paper for more information on the assumptions and the method. See Rounding for more information on how to use the rounding implementation. ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Since we expect the solution to be relatively nice in terms of polynomials, we avoid doing the basis change generated by approximatefekete, and try to find the field using the following code. ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"obj, problem, primalsol, dualsol = min_f(f, ws, 2; basis_change=false)\nN, gapprox = find_field(primalsol, dualsol)\nN","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We find a field of degree 2. Trying to round the objective to this field gives","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"to_field(obj, N, gapprox)\nprintln(ans)# stuff to print it nicely since Nemo doesn't print nicely # hide","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Since this is a small expression, this gives some indication that N is the correct field. Now we will try to round the numerical solution to this field. First we convert the problem to the field N. This can be done using the function generic_embedding. ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"problem = map(x->generic_embedding(x, gen(N), base_ring=N), problem)\nnothing # hide","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In general it is advisable to use coefficient matching to define the semidefinite program for the rounding procedure. For this we need to build a monomial basis for each constraint. ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"R, x = polynomial_ring(N, 4)\nmonbasis = basis_monomial(4, x...)\nnothing # hide","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Then we are ready to try the rounding procedure. This will not always succeed without tuning the settings, but in this example it does. See the Rounding page for information on the settings.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"success, exactdualsol = exact_solution(problem, primalsol, dualsol;\n        FF=N, g=gapprox, monomial_bases=[monbasis])\nnothing # hide","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"If success is true, the solution exactdualsol is guaranteed to be feasible. The affine constraints have been checked in exact arithmetic, and positive semidefiniteness has been checked in ball arithmetic.   We can check that we get the same objective as directly rounding the objective to the field N.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"objvalue(problem, exactdualsol)\nprintln(ans)# stuff to print it nicely since Nemo doesn't print nicely # hide","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The output of the rounding procedure to the terminal contains some information about the number of kernel vectors and the largest numbers in absolute value occuring in those kernel vectors, some progress messages, and some messages about the system that is solved.  ","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"find_field\nexact_solution","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.find_field-tutorial","page":"Tutorial","title":"ClusteredLowRankSolver.find_field","text":"find_field(primalsol, dualsol, max_degree=4; valbound=1e-15, errbound=1e-15, bits=100, max_coeff=1000)\n\nHeuristically find a field over which the kernel can probably be defined. \n\nOnly consider values at least valbound in absolute value. Find minimal polynomials  such that the chosen entries are approximately generators with an error bound of errbound. Use bits number of bits and reject minimal polynomials with a maximum coefficient of more than max_coeff.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.exact_solution-tutorial","page":"Tutorial","title":"ClusteredLowRankSolver.exact_solution","text":"exact_solution(problem::Problem, primalsol::PrimalSolution, dualsol::DualSolution; transformed=false, FF = QQ, g=1, settings::RoundingSettings=RoundingSettings(), monomial_bases=nothing)\n\nCompute and return an exact solution to the problem, given a primal solution, dual solution and a field FF with approximate generator g. Return (success, exactdualsol) if transformed=false, and (success, pd_transformed_exactsolution, transformations) if transformed=true.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"generic_embedding\nto_field","category":"page"},{"location":"tutorial/#ClusteredLowRankSolver.generic_embedding","page":"Tutorial","title":"ClusteredLowRankSolver.generic_embedding","text":"generic_embedding(exactvalue, g; base_ring=BigFloat)\n\nConvert the exact numbers from a number field to floating point approximations,  using a floating point approximation of a generator g of the field.\n\nConvert rationals and integers to the same numbers in base_ring.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#ClusteredLowRankSolver.to_field","page":"Tutorial","title":"ClusteredLowRankSolver.to_field","text":"to_field(v, N, g; bits=100, errbound=1e-15)\n\nFind an approximation of v in the number field N, using the approximate generator g of N.\n\n\n\n\n\n","category":"function"}]
}
